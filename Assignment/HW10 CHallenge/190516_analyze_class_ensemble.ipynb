{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT PYTHON PACKAGES**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import csv\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)                                          # suppress warnings related to older versions of some packages that we need to use to run flopy\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)                                       # suppress warnings related to older versions of some packages that we need to use to run flopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USER-DEFINED SETTINGS**\n",
    "   (Make changes here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d63975a5f832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mbehavioral_criteria\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0min_time_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_basis_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_comparison_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_limit_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_column_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_row_sequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mcomparison_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'behavioral_criteria'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbehavioral_criteria\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#save behavioral criteria to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comparison_directory' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "stakeholder='env'                                                                                      # choose from ag/town/env\n",
    "stage='combine'                                                                                        # choose from random/reseed/combined/afterdata\n",
    "prefix = stakeholder + '_' + stage + '_'      #generates filename prefix\n",
    "\n",
    "def output_directory():     # use this to define where your output files reside\n",
    "#     os.chdir(r'C:\\Users\\TyFerre\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output')               # home computer\n",
    "#    os.chdir(r'C:\\Users\\PC\\Desktop\\Ty\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output')       # office computer\n",
    "#     os.chdir(r'D:\\Ty\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output')       # office computer\n",
    "     os.chdir(r'C:\\Users\\Dalia\\OneDrive\\Documents\\SPRING21\\582-GWMod\\hws-PortilloD\\Assignment\\HW10 CHallenge\\output')       # alien computer\n",
    "def figure_directory():     # use this to define where to put your figure files \n",
    "#     os.chdir(r'C:\\Users\\TyFerre\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\figures')\n",
    "#    os.chdir(r'C:\\Users\\PC\\Desktop\\Ty\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\figures')\n",
    "#     os.chdir(r'D:\\Ty\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\figures')       # office computer\n",
    "     os.chdir(r'C:\\Users\\Dalia\\OneDrive\\Documents\\SPRING21\\582-GWMod\\hws-PortilloD\\Assignment\\HW10 CHallenge\\figures')       # office computer\n",
    "# def comparison_directory():\n",
    "#     os.chdir(r'C:\\Users\\TyFerre\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\paper\\likelihood')  # change last two subdirectories for each run random/reseed/afterdata and ag/town/env with \n",
    "#    os.chdir(r'C:\\Users\\PC\\Desktop\\Ty\\tyfiles\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\paper\\likelihood')\n",
    "#     os.chdir(r'D:\\Ty\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\paper\\likelihood')       # office computer\n",
    "#      os.chdir(r'D:\\tyferre\\frequent\\GWV7\\Models\\HWR528\\fromTroels\\output\\paper\\likelihood')       # office computer\n",
    "    \n",
    "displaycolumn=40                                                                                      # column for head and drawdown analysis\n",
    "displayrow=30                                                                                         # row for head and drawdown analysis\n",
    "\n",
    "# put obs well at town well\n",
    "displaycolumn=20                                                                                      # column for head and drawdown analysis\n",
    "displayrow=37                                                                                         # row for head and drawdown analysis\n",
    "\n",
    "strdisplaycolumn=35                                                                                   # column for streamflow analysis\n",
    "\n",
    "minmismatch=0.05                                                                                      # don't consider mismatches that are less than this value - avoids unrealistically high likelihoods\n",
    "                                                                                                      # define criteria to meet to qualify as behavioral ... if a model PASSES this test it is behavioral\n",
    "in_time_sequence =       [1,1,1]                                                                      # 0=ntna, 1=ytna, 2=ytya ... enter a number for each criterion applied\n",
    "in_basis_sequence =      [0,0,1]                                                                      # see list below\n",
    "in_comparison_sequence = [1,0,1]                                                                      # 0 = greater than, 1 = less than\n",
    "in_limit_sequence =      [2000,10,3]                                                                  # value defining behavioral response\n",
    "in_column_sequence =     [15,15,15]                                                                   # column of observation point for basis 2 or 3  - must have a value for every criterion, even if not used\n",
    "in_row_sequence =        [15,15,15]                                                                   # row of observation point for basis 2 or 3 - must have a value for every criterion, even if not used\n",
    "                  \n",
    "behavioral_criteria = [in_time_sequence, in_basis_sequence, in_comparison_sequence, in_limit_sequence, in_column_sequence, in_row_sequence]\n",
    "comparison_directory()\n",
    "np.save(prefix + 'behavioral_criteria',behavioral_criteria) #save behavioral criteria to a file\n",
    "output_directory()\n",
    "\n",
    "define_mocs = True                                                                                    # define criteria to meet to qualify as an MOC ... if a model PASSES this test it is a model of concern (MOC)\n",
    "if stakeholder=='town':\n",
    "    moc_time_sequence =       [2]                                                                       # 0=ntna, 1=ytna, 2=ytya ... enter a number for each criterion applied\n",
    "    moc_basis_sequence =      [4]                                                                       # see list below\n",
    "    moc_comparison_sequence = [0]                                                                       # 0 = greater than, 1 = less than\n",
    "    moc_limit_sequence =      [0.5]                                                                   # value defining behavioral response\n",
    "    moc_column_sequence =     [37]                                                                     # column of observation point for basis 2 or 3  - must have a value for every criterion, even if not used\n",
    "    moc_row_sequence =        [20]                                                                     # row of observation point for basis 2 or 3 - must have a value for every criterion, even if not used\n",
    "elif stakeholder=='ag':\n",
    "    moc_time_sequence =       [2]                                                                       # 0=ntna, 1=ytna, 2=ytya ... enter a number for each criterion applied\n",
    "    moc_basis_sequence =      [3]                                                                       # see list below\n",
    "    moc_comparison_sequence = [1]                                                                       # 0 = greater than, 1 = less than\n",
    "    moc_limit_sequence =      [68]                                                                   # value defining behavioral response\n",
    "    moc_column_sequence =     [13]                                                                     # column of observation point for basis 2 or 3  - must have a value for every criterion, even if not used\n",
    "    moc_row_sequence =        [11]                                                                     # row of observation point for basis 2 or 3 - must have a value for every criterion, even if not used\n",
    "elif stakeholder=='env':\n",
    "    moc_time_sequence =       [2]                                                                       # 0=ntna, 1=ytna, 2=ytya ... enter a number for each criterion applied\n",
    "    moc_basis_sequence =      [2]                                                                       # see list below\n",
    "    moc_comparison_sequence = [1]                                                                       # 0 = greater than, 1 = less than\n",
    "    moc_limit_sequence =      [50]                                                                   # value defining behavioral response\n",
    "    moc_column_sequence =     [38]                                                                     # column of observation point for basis 2 or 3  - must have a value for every criterion, even if not used\n",
    "    moc_row_sequence =        [25]                                                                     # row of observation point for basis 2 or 3 - must have a value for every criterion, even if not used\n",
    "\n",
    "# we should add the ability to have an MOC criterion in other than layer 1!!\n",
    "# add criterion for flow reduction\n",
    "\n",
    "#   BASES FOR DETERMINATION OF BEHAVIORAL MODEL\n",
    "#       0 = max streamflow along stream\n",
    "#       1 = min groundwater depth over first layer\n",
    "#       2 = streamflow at specified location\n",
    "#       3 = head at specified location\n",
    "#       4 = drawdown at specified location\n",
    "                                                                                                      # use empty brackets if no data available, each value must contain the same number of inputs, separate multiple data points by commas\n",
    "moc_criteria = [moc_time_sequence, moc_basis_sequence, moc_comparison_sequence, moc_limit_sequence, moc_column_sequence, moc_row_sequence]\n",
    "comparison_directory()\n",
    "np.save(prefix + 'moc_criteria',moc_criteria) #save moc criteria to a file\n",
    "output_directory()\n",
    "\n",
    "read_true_data=True                                                                                   # True to read in the observations from truth_heads_ss_ytna.npy and truth_flows_ss_ytna.npy\n",
    "if read_true_data==True:\n",
    "    output_directory()\n",
    "    trueheads_ss_ytna=np.load('truth_heads_ss_ytna.npy')[0][:][:]\n",
    "    trueflows_ss_ytna=np.load('truth_strflow_ss_ytna.npy')[:]\n",
    "\n",
    "usedata = True                                                                                        # set to true to use available data to calculate likelihoods, false to set models as equally likely\n",
    "data_time_sequence = [1,1]                                                                            # 0 = ntna, 1 = ytna, 2 = ytya\n",
    "data_basis_sequence =[1,1]                                                                            # identify head or flow observation\n",
    "data_layer_sequence = [0,0]                                                                           # layer of head observation - enter zero for flow\n",
    "data_column_sequence = [35,20]                                                                        # column of head or flow observation\n",
    "data_row_sequence = [20,30]                                                                           # row of head or flow observation\n",
    "data_value_sequence = np.zeros((np.shape(data_row_sequence)))\n",
    "for ii in np.arange(np.shape(data_row_sequence)[0]):                                                              \n",
    "    if data_basis_sequence[ii]==1:\n",
    "        data_value_sequence[ii]=trueheads_ss_ytna[data_row_sequence[ii],data_column_sequence[ii]]     # Retrieve head data in top layer from the 'truth' model\n",
    "    elif data_basis_sequence[ii]==0:\n",
    "        data_value_sequence[ii]=trueflows_ss_ytna[data_column_sequence[ii]][1]                        # Retrieve flow data in stream from the 'truth' model\n",
    "        \n",
    "#   TYPES OF OBSERVATION DATA CONSIDERED\n",
    "#       0 = streamflow at specified location\n",
    "#       1 = head at specified location\n",
    "\n",
    "if usedata==True:\n",
    "    num_data=np.shape(data_time_sequence)[0]\n",
    "else:\n",
    "    num_data=0\n",
    "\n",
    "eliminate_lowL_models=True                                                                            # True to eliminate low Likelihood models from the ensemble - for now, always set to true, but set number to eliminate to zero to turn off\n",
    "lowLcut_percent=10                                                                                    # remove this percent of models with the lowest L values\n",
    "lowLcut_number=0                                                                                      # don't remove any more than this number of models, no matter how low their L value, despite above limit\n",
    "lowLlimit=0.05                                                                                        # don't remove models with an L higher than this, despite above limits\n",
    "lowLecho=True                                                                                         # True to list the low L models, False to suppress (in case you have a lot!)\n",
    "\n",
    "#Export files needed for multi-stakeholder comparisons:\n",
    "#To import, use np.load()\n",
    "comparison_directory()               #change directory to current stakeholder and stage\n",
    "np.save(prefix + 'data_layer', data_layer_sequence)\n",
    "np.save(prefix + 'data_row', data_row_sequence)\n",
    "np.save(prefix + 'data_column', data_column_sequence)\n",
    "output_directory()\n",
    "\n",
    "# use the following to control which analyses are completed - may be useful when running partial analyses for many models\n",
    "run_sections=1\n",
    "\n",
    "# 0 = through identifying behavioral models and calculating model likelihoods\n",
    "# 1 = identify models of concern\n",
    "# 2 - calculate discriminatory index\n",
    "# 3 - particle capture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    in_time_sequence, in_basis_sequence, in_layer_sequence, in_column_sequence, in_value_sequence\n",
    "    moc_time_sequence, moc_basis_sequence, moc_layer_sequence, moc_column_sequence, moc_value_sequence\n",
    "    data_time_sequence, data_basis_sequence, data_layer_sequence, data_column_sequence, data_value_sequence\n",
    "  \n",
    "    define_mocs, usedata, eliminate_lowL_models, \n",
    "    displaycolumn, displayrow, strdisplaycolumn\n",
    "    minmismatch\n",
    "    lowLcut_percent, lowLcut_number, lowLlimit, lowLecho \n",
    "  \n",
    "    num_data\n",
    "  \n",
    "    trueheads_ss_ytna, trueflows_ss_ytna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ IN ALL MODELS IN OUTPUT DIRECTORY FOR ANALYSIS**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(os.curdir)                                                                         # all files in output directory\n",
    "counter=-1                                                                                            # used to step through files\n",
    "runcounter=-1                                                                                         # used to count number of steady state models \n",
    "t_runcounter=-1                                                                                       # used to count number of transient models\n",
    "runnumbers=[]                                                                                         # file ids for steady state models\n",
    "t_runnumbers=[]                                                                                       # file ids for transient models\n",
    "holdtempvar=[]                                                                                        # previous model file analyzed - used to indicate next steady state model found\n",
    "t_holdtempvar=[]                                                                                      # previous model file analyzed - used to indicate next transient model found\n",
    "\n",
    "for f in files:                                                                                       # loop over all models in directory\n",
    "    counter=counter+1\n",
    "    if files[counter][0]=='m':                                                                        # only consider output model files\n",
    "        try:                                                                                          # check for steady state models\n",
    "            if files[counter][16]=='_':\n",
    "                tempvar=files[counter][0:16]\n",
    "                if counter==-1:\n",
    "                    holdtempvar=tempvar\n",
    "                elif holdtempvar!=tempvar: \n",
    "                    runcounter=runcounter+1\n",
    "                    runnumbers.append(tempvar)                                                        # make a list of run names\n",
    "                    holdtempvar=tempvar\n",
    "        except:\n",
    "            dummy=0\n",
    "            \n",
    "        try:                                                                                          # check for transient models\n",
    "            if files[counter][16:26]=='_heads_pod':     \n",
    "                t_tempvar=files[counter][0:16]\n",
    "                if counter==-1:\n",
    "                    t_holdtempvar=t_tempvar\n",
    "                elif t_holdtempvar!=t_tempvar: \n",
    "                    t_runcounter=t_runcounter+1\n",
    "                    t_runnumbers.append(t_tempvar)\n",
    "                    t_holdtempvar=t_tempvar\n",
    "        except:\n",
    "            dummy=0\n",
    "            \n",
    "del counter                                                                                           # clear temporary variables\n",
    "del runcounter\n",
    "del t_runcounter\n",
    "del holdtempvar\n",
    "del t_holdtempvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    runnumbers, t_runnumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASIC INPUT FOR PLOT FEATURES**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_params=np.zeros((np.shape(runnumbers)[0],7))                                                      # prepare an array to store parameter values that differ among model runs\n",
    "for i in np.arange(np.shape(runnumbers)[0]):                                                          # loop over models to read parameter values from parvals file - not used for now, but may be\n",
    "    with open (runnumbers[i]+'_parvals', 'rb') as fp:\n",
    "        [nrow,ncol,delr,delc,Lx,Ly,nlay,ztop,crop,fNWc,well1,well2,recharge_ratio,return_loc,\n",
    "             rNWc, K_horiz, Kzratio_low, Sy, R1, ET1, ETratio_riparian, Kratio_stream] = pickle.load(fp)\n",
    "        run_params[i,0]=K_horiz\n",
    "        run_params[i,1]=Kzratio_low\n",
    "        run_params[i,2]=Sy\n",
    "        run_params[i,3]=R1\n",
    "        run_params[i,4]=ET1\n",
    "        run_params[i,5]=ETratio_riparian\n",
    "        run_params[i,6]=Kratio_stream\n",
    "\n",
    "# assume well and recharge and return flow locations same for all runs and that the following are unchanged - eventually, include these in the parvals file\n",
    "nreach = 48+1                                                                                         # number of reaches (# of cells in stream + 1 canal reach) \n",
    "strrow=25                                                                                             # row in which stream resides\n",
    "reaches = np.arange(ncol-1)                                                                           # for plotting flow along stream\n",
    "str_rows = strrow*np.ones((nreach),dtype=np.int32)                                                    # integer array of row #s for each stream reach \n",
    "str_cols = np.arange(1,nreach+1)                                                                      # integer array of col #s for each stream reach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    run_params\n",
    "    nreach, strrow, reaches, str_rows, str_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT MODEL RESULTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allheads_ss_ntna=np.zeros((len(runnumbers),50,50))                                                   # initialize arrays to accept all heads for each ss run\n",
    "allheads_ss_ytna=np.zeros((len(runnumbers),50,50))\n",
    "allheads_ss_ytya=np.zeros((len(runnumbers),50,50))\n",
    "allbudgets_ss_ntna=np.zeros((len(runnumbers),16))                                                    # initialize arrays to accept all heads for each ss run\n",
    "allbudgets_ss_ytna=np.zeros((len(runnumbers),16))\n",
    "allbudgets_ss_ytya=np.zeros((len(runnumbers),16))\n",
    "budget=np.zeros((7))\n",
    "for i in range(len(runnumbers)):\n",
    "    heads=np.load(runnumbers[i]+'_heads_ss_ntna.npy')[0][:][:]                                       # use heads in top layer\n",
    "    allheads_ss_ntna[i][:][:]=heads\n",
    "    heads=np.load(runnumbers[i]+'_heads_ss_ytna.npy')[0][:][:]\n",
    "    allheads_ss_ytna[i][:][:]=heads\n",
    "    heads=np.load(runnumbers[i]+'_heads_ss_ytya.npy')[0][:][:]\n",
    "    allheads_ss_ytya[i][:][:]=heads\n",
    "    budget=np.load(runnumbers[i]+'_budget_ss_ntna.npy')\n",
    "    for j in np.arange(16):\n",
    "        allbudgets_ss_ntna[i][j]=budget[j][1]\n",
    "    budget=np.load(runnumbers[i]+'_budget_ss_ytna.npy')\n",
    "    for j in np.arange(16):\n",
    "        allbudgets_ss_ytna[i][j]=budget[j][1]\n",
    "    budget=np.load(runnumbers[i]+'_budget_ss_ytya.npy')\n",
    "    for j in np.arange(16):\n",
    "        allbudgets_ss_ytya[i][j]=budget[j][1]\n",
    "\n",
    "# budget components are:\n",
    "# 0: STORAGE_IN\n",
    "# 1: CONSTANT_HEAD_IN\n",
    "# 2: WELLS_IN\n",
    "# 3: ET_IN\n",
    "# 4: RECHARGE_IN\n",
    "# 5: STREAM_LEAKAGE_IN\n",
    "# 6: TOTAL_IN\n",
    "# 7: STORAGE_OUT\n",
    "# 8: CONSTANT_HEAD_OUT\n",
    "# 9: WELLS_OUT\n",
    "#10: ET_OUT\n",
    "#11: RECHARGE_OUT\n",
    "#12: STREAM_LEAKAGE_OUT\n",
    "#13: TOTAL_OUT\n",
    "#14: IN-OUT\n",
    "#15: PERCENT_DISCREPANCY\n",
    "\n",
    "allheads_ss_ntna[allheads_ss_ntna<0]=0                                                               # remove the corners as they confused the standard deviation calculation\n",
    "allheads_ss_ytna[allheads_ss_ytna<0]=0\n",
    "allheads_ss_ytya[allheads_ss_ytya<0]=0\n",
    "\n",
    "alldwt_ss_ntna=np.zeros((len(runnumbers),50,50))                                                     # initialize arrays to accept all water table depths for each ss run\n",
    "alldwt_ss_ytna=np.zeros((len(runnumbers),50,50))     \n",
    "alldwt_ss_ytya=np.zeros((len(runnumbers),50,50))     \n",
    "maxdwt_ss_ntna=np.zeros((len(runnumbers)))                                                           # initialize arrays to accept maximum water table depth for each ss run\n",
    "maxdwt_ss_ytna=np.zeros((len(runnumbers)))           \n",
    "maxdwt_ss_ytya=np.zeros((len(runnumbers)))           \n",
    "\n",
    "for i in np.arange(np.shape(allheads_ss_ntna)[0]):                                                   # calculate depths of the water table\n",
    "    tempvar=allheads_ss_ntna[i,:,:]-ztop \n",
    "    alldwt_ss_ntna[i,:,:]=tempvar\n",
    "    maxdwt_ss_ntna[i]=np.max(tempvar)\n",
    "    tempvar=allheads_ss_ytna[i,:,:]-ztop \n",
    "    alldwt_ss_ytna[i,:,:]=tempvar\n",
    "    maxdwt_ss_ytna[i]=np.max(tempvar)\n",
    "    tempvar=allheads_ss_ytya[i,:,:]-ztop \n",
    "    alldwt_ss_ytya[i,:,:]=tempvar\n",
    "    maxdwt_ss_ytya[i]=np.max(tempvar)\n",
    "\n",
    "dd=allheads_ss_ytna-allheads_ss_ytya                                                                 # define drawdown for each model at each location in top layer from ytna and ytya \n",
    "\n",
    "allflows_ss_ntna=np.zeros((len(runnumbers),49))                                                      # initialize arrays to accept all flows for each ss run   \n",
    "allflows_ss_ytna=np.zeros((len(runnumbers),49))\n",
    "allflows_ss_ytya=np.zeros((len(runnumbers),49))\n",
    "    \n",
    "for i in range(len(runnumbers)):\n",
    "    flows=np.load(runnumbers[i]+'_strflow_ss_ntna.npy')                                              # import flows at each stream cell across models for ntna\n",
    "    flow = []\n",
    "    for tup in range(len(flows)):\n",
    "        flow.append(flows[tup][1])\n",
    "    allflows_ss_ntna[i][:][:] = flow\n",
    "\n",
    "    flows=np.load(runnumbers[i]+'_strflow_ss_ytna.npy')\n",
    "    flow = []\n",
    "    for tup in range(len(flows)):\n",
    "        flow.append(flows[tup][1])\n",
    "    allflows_ss_ytna[i][:][:]=flow\n",
    "    \n",
    "    flows=np.load(runnumbers[i]+'_strflow_ss_ytya.npy')\n",
    "    flow = []\n",
    "    for tup in range(len(flows)):\n",
    "        flow.append(flows[tup][1])\n",
    "    allflows_ss_ytya[i][:][:]=flow\n",
    "\n",
    "allleaks_ss_ntna=np.zeros((len(runnumbers),49))                                                      # initialize arrays to accept all flows for each ss run   \n",
    "allleaks_ss_ytna=np.zeros((len(runnumbers),49))\n",
    "allleaks_ss_ytya=np.zeros((len(runnumbers),49))\n",
    "    \n",
    "for i in range(len(runnumbers)):\n",
    "    leaks=np.load(runnumbers[i]+'_strleak_ss_ntna.npy')                                              # import leakage at each stream cell across models for ntna\n",
    "    leak = []\n",
    "    for tup in range(len(leaks)):\n",
    "        leak.append(leaks[tup][1])\n",
    "    allleaks_ss_ntna[i][:][:] = leak\n",
    "\n",
    "    leaks=np.load(runnumbers[i]+'_strleak_ss_ytna.npy')\n",
    "    leak = []\n",
    "    for tup in range(len(leaks)):\n",
    "        leak.append(leaks[tup][1])\n",
    "    allleaks_ss_ytna[i][:][:]=leak\n",
    "    \n",
    "    leaks=np.load(runnumbers[i]+'_strleak_ss_ytya.npy')\n",
    "    leak = []\n",
    "    for tup in range(len(leaks)):\n",
    "        leak.append(leaks[tup][1])\n",
    "    allleaks_ss_ytya[i][:][:]=leak\n",
    "    \n",
    "testepts=np.load(runnumbers[0]+'_epts_ss_ytna.npy')                                                  # read this file to set dimensions of arrays in next lines\n",
    "allepts_ss_ntna=np.zeros((np.shape(runnumbers)[0],np.shape(testepts)[0],np.shape(testepts)[1]))      # initialize arrays to accept all particle data for each ss run \n",
    "allepts_ss_ytna=np.zeros((np.shape(runnumbers)[0],np.shape(testepts)[0],np.shape(testepts)[1]))     \n",
    "allepts_ss_ytya=np.zeros((np.shape(runnumbers)[0],np.shape(testepts)[0],np.shape(testepts)[1]))     \n",
    "\n",
    "counter=-1\n",
    "for i in runnumbers:                                       \n",
    "    counter=counter+1                                                                                # count the models as loaded to form joint array with all models' results\n",
    "    epts=np.load(i+'_epts_ss_ntna.npy')                                                              # load output for each model in ensemble\n",
    "    \n",
    "    for j in np.arange(np.shape(testepts)[0]):\n",
    "        allepts_ss_ntna[counter,j,0]=epts[j][8]                                                      # start point column (all particles assumed to start in top layer, as recharge)\n",
    "        allepts_ss_ntna[counter,j,1]=epts[j][7]                                                      # start point row \n",
    "        allepts_ss_ntna[counter,j,2]=epts[j][20]                                                     # end point column \n",
    "        allepts_ss_ntna[counter,j,3]=epts[j][19]                                                     # end point row \n",
    "        allepts_ss_ntna[counter,j,4]=epts[j][4]                                                      # end point time \n",
    "    epts=np.load(i+'_epts_ss_ytna.npy')  \n",
    "    for j in np.arange(np.shape(testepts)[0]):\n",
    "        allepts_ss_ytna[counter,j,0]=epts[j][8]            \n",
    "        allepts_ss_ytna[counter,j,1]=epts[j][7]            \n",
    "        allepts_ss_ytna[counter,j,2]=epts[j][20]           \n",
    "        allepts_ss_ytna[counter,j,3]=epts[j][19]           \n",
    "        allepts_ss_ytna[counter,j,4]=epts[j][4]       \n",
    "    epts=np.load(i+'_epts_ss_ytya.npy')  \n",
    "    for j in np.arange(np.shape(testepts)[0]):\n",
    "        allepts_ss_ytya[counter,j,0]=epts[j][8]            \n",
    "        allepts_ss_ytya[counter,j,1]=epts[j][7]            \n",
    "        allepts_ss_ytya[counter,j,2]=epts[j][20]           \n",
    "        allepts_ss_ytya[counter,j,3]=epts[j][19]          \n",
    "        allepts_ss_ytya[counter,j,4]=epts[j][4]       \n",
    "        \n",
    "allflows_ss_ntna = np.delete(allflows_ss_ntna, return_loc,axis=1)                                    # remove reach used as canal to return town water to stream\n",
    "allflows_ss_ytna = np.delete(allflows_ss_ytna, return_loc,axis=1)\n",
    "allflows_ss_ytya = np.delete(allflows_ss_ytya, return_loc,axis=1)\n",
    "\n",
    "del heads                                                                                            # clear temporary variables\n",
    "del tempvar\n",
    "del flow\n",
    "del flows\n",
    "del leak\n",
    "del leaks\n",
    "del testepts\n",
    "del counter\n",
    "del epts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    allheads_ss_ntna, allheads_ss_ytna, allheads_ss_ytya\n",
    "    allbudgets_ss_ntna, allbudgets_ss_ytna, allbudgets_ss_ytya\n",
    "    allepts_ss_ntna, allepts_ss_ytna, allepts_ss_ytya\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** COMPILE DATA TO ASSESS (NON)BEHAVIORAL MODELS **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cullmodels=np.zeros((np.shape(runnumbers)[0],50))                                                    # store values used to assess (non)behavioural and likelihood to check process\n",
    "cullmodels_counter=-1\n",
    "\n",
    "num_criteria=0\n",
    "if 'in_time_sequence' in locals():\n",
    "    num_criteria=np.shape(in_time_sequence)[0]                                                       # determine number of criteria to that have been applied\n",
    "\n",
    "if num_criteria>0:\n",
    "    print('Assessing (non)behavioral criteria')\n",
    "    for ii in np.arange(num_criteria):                                                               # loop over bases for discrimination of models of concern or (non)behavioral models\n",
    "        cullmodels_counter=cullmodels_counter+1\n",
    "        print('Assessing criterion',ii)\n",
    "        in_time=in_time_sequence[ii]\n",
    "        in_basis=in_basis_sequence[ii]\n",
    "        in_comparison=in_comparison_sequence[ii]\n",
    "        in_limit=in_limit_sequence[ii]\n",
    "        in_column=in_column_sequence[ii]\n",
    "        in_row=in_row_sequence[ii]\n",
    "\n",
    "        if in_basis==0:\n",
    "            in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))\n",
    "            if in_time==0:\n",
    "                in_metric=np.max(allflows_ss_ntna,axis=1)                                            # store maximum flow for each model for ntna case\n",
    "            elif in_time==1:\n",
    "                in_metric=np.max(allflows_ss_ytna,axis=1)                                            # store maximum flow for each model for ytna case\n",
    "            else:\n",
    "                in_metric=np.max(allflows_ss_ytya,axis=1)                                            # store maximum flow for each model for ytya case\n",
    "        elif in_basis==1:\n",
    "            in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))     \n",
    "            if in_time==0:\n",
    "                in_metric=maxdwt_ss_ntna                                                             # store minimum flow for each model for ntna case\n",
    "            elif in_time==1:\n",
    "                in_metric=maxdwt_ss_ytna                                                             # store minimum flow for each model for ytna case\n",
    "            else:\n",
    "                in_metric=in_metric=maxdwt_ss_ytya                                                   # store minimum flow for each model for ytya case\n",
    "        elif in_basis==2:\n",
    "            in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))     \n",
    "            if in_time==0:\n",
    "                for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allflows_ss_ntna[j][in_column]                                      # store flow at specified location for each model for ntna case\n",
    "            elif in_time==1:\n",
    "                for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allflows_ss_ytna[j][in_column]                                      # store flow at specified location for each model for ntna case\n",
    "            else:\n",
    "                for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allflows_ss_ytya[j][in_column]                                      # store flow at specified location for each model for ntna case\n",
    "        elif in_basis==3:\n",
    "            in_metric=np.zeros((np.shape(allheads_ss_ntna)[0]))     \n",
    "            if in_time==0:\n",
    "                for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allheads_ss_ntna[j][in_row][in_column]                              # store flow at specified location for each model for ntna case\n",
    "            elif in_time==1:\n",
    "                for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allheads_ss_ytna[j][in_row][in_column]                              # store flow at specified location for each model for ntna case\n",
    "            else:\n",
    "                for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                    in_metric[j]=allheads_ss_ytya[j][in_row][in_column]                              # store flow at specified location for each model for ntna case\n",
    "        else:\n",
    "            in_metric=np.zeros((np.shape(dd)[0]))     \n",
    "            if in_time==0:\n",
    "                for j in np.arange(np.shape(dd)[0]):                \n",
    "                    in_metric[j]=dd[j][in_row][in_column]                                            # store flow at specified location for each model for ntna case\n",
    "            elif in_time==1:\n",
    "                for j in np.arange(np.shape(dd)[0]):                \n",
    "                    in_metric[j]=dd[j][in_row][in_column]                                            # store flow at specified location for each model for ntna case\n",
    "            else:\n",
    "                for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                    in_metric[j]=dd[j][in_row][in_column]                                            # store flow at specified location for each model for ntna case\n",
    "\n",
    "        cullmodels[:,cullmodels_counter]=in_metric                                                   # store data used to check (non)behavioral status\n",
    "\n",
    "    del num_criteria                                                                                 # clear temporary variables\n",
    "    del in_time\n",
    "    del in_basis\n",
    "    del in_comparison\n",
    "    del in_limit\n",
    "    del in_column\n",
    "    del in_row\n",
    "    del in_metric\n",
    "\n",
    "else:\n",
    "    print('No (non)behavioral criteria listed')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    cullmodels, cullmodels_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** COMPILE DATA TO ASSESS MODEL LIKELIHOODS **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdata=cullmodels_counter+1                                                                     # index in cullmodels that is start of data for likelihood estimation\n",
    "holdfordataworth=np.zeros((num_data,np.shape(allflows_ss_ntna)[0]))\n",
    "if usedata==True:\n",
    "    num_data=np.shape(data_time_sequence)[0]\n",
    "    if num_data>0:                                                                                 # if there are data for comparison, calculate likelihoods\n",
    "        for jj in np.arange(np.shape(allflows_ss_ntna)[0]):   \n",
    "            for ii in np.arange(num_data):                                                         # loop over bases for discrimination\n",
    "                in_basis=data_basis_sequence[ii]\n",
    "                in_time=data_time_sequence[ii]\n",
    "                if in_basis==0:                                                                    # note that squared mismatch sums over all observations\n",
    "                    if in_time==0:\n",
    "                        data2check=allflows_ss_ntna[jj][data_row_sequence[ii]][data_column_sequence[ii]]\n",
    "                    elif in_time==1:\n",
    "                        data2check=allflows_ss_ytna[jj][data_row_sequence[ii]][data_column_sequence[ii]]\n",
    "                    else:\n",
    "                        data2check=allflows_ss_ytya[jj][data_row_sequence[ii]][data_column_sequence[ii]]\n",
    "                else:\n",
    "                    if in_time==0:\n",
    "                        data2check=allheads_ss_ntna[jj][data_row_sequence[ii]][data_column_sequence[ii]]\n",
    "                    elif in_time==1:\n",
    "                        data2check=allheads_ss_ytna[jj][data_row_sequence[ii]][data_column_sequence[ii]]\n",
    "                    else:\n",
    "                        data2check=allheads_ss_ytya[jj][data_row_sequence[ii]][data_column_sequence[ii]]        \n",
    "                cullmodels[jj,cullmodels_counter+1+ii]=data2check\n",
    "                holdfordataworth[ii,jj]=data2check\n",
    "        del in_time                                                                                # clear temporary variables\n",
    "        del in_basis\n",
    "        del data2check\n",
    "        np.save(prefix + 'holdfordataworth', holdfordataworth)\n",
    "\n",
    "    else:     \n",
    "        dummy=0\n",
    "        del dummy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    startdata\n",
    "    cullmodels, cullmodels_counter\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATE MODEL LIKELIHOODS - SET NONBEHAVIORAL TO LOW L **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=np.zeros((np.shape(runnumbers)[0]))                                                          # use model rmse to flag nonbehavioral models below\n",
    "L = 1/np.shape(allflows_ss_ntna)[0]                                                               # set likelihoods equal if there as default, keep if there are no data\n",
    "L=np.tile(L,np.shape(allflows_ss_ntna)[0])\n",
    "if usedata==True:\n",
    "    if np.shape(data_time_sequence)[0]>0:\n",
    "        cullmodels_counter=cullmodels_counter+num_data                                            # need to advance counter here because of looping structure above\n",
    "        mmsqsum=0\n",
    "        for i in np.arange(np.shape(data_time_sequence)[0]):                                      # loop over number of data used to calculate L\n",
    "            cullmodels_counter=cullmodels_counter+1\n",
    "            mmsq=((cullmodels[:,i+startdata]-data_value_sequence[i])**2)                          # square mismatch for first data point\n",
    "            cullmodels[:,cullmodels_counter]=mmsq                                                 # store square mismatches for later checking\n",
    "            mmsqsum=mmsqsum+mmsq                                                                  # sum square mismatches\n",
    "        rmse=(mmsqsum/(i+1))**0.5                                                                 # calculate root mean square mismatch\n",
    "\n",
    "        cullmodels_counter=cullmodels_counter+1\n",
    "        cullmodels[:,cullmodels_counter]=rmse                                                     # store rmse\n",
    "        for i in np.arange(np.shape(in_time_sequence)[0]):                                        # set likelihoods of nonbehavioral models to near-zero by setting rmse very high\n",
    "            if in_comparison_sequence[i]==0:\n",
    "                rmse[cullmodels[:,i]<=in_limit_sequence[i]]=1.2345e9\n",
    "            else:\n",
    "                rmse[cullmodels[:,i]>=in_limit_sequence[i]]=1.2345e9\n",
    "        cullmodels_counter=cullmodels_counter+1\n",
    "        cullmodels[:,cullmodels_counter]=rmse                                                     # store rmse after culling non-behavioral models\n",
    "        Ltemp=1/rmse                                                                              # invert rmse as first step to calculating L\n",
    "        L=Ltemp/np.sum(Ltemp)\n",
    "        cullmodels_counter=cullmodels_counter+1\n",
    "        cullmodels[:,cullmodels_counter]=L                                                        # calculate and store L\n",
    "        del mmsq                                                                                          # clear temporary variables\n",
    "        del mmsqsum\n",
    "        del Ltemp\n",
    "else:\n",
    "    for i in np.arange(np.shape(in_time_sequence)[0]):                                            # set likelihoods of nonbehavioral models to near-zero by setting rmse very high\n",
    "        if in_comparison_sequence[i]==0:\n",
    "            rmse[cullmodels[:,i]<=in_limit_sequence[i]]=1.2345e9\n",
    "        else:\n",
    "            rmse[cullmodels[:,i]>=in_limit_sequence[i]]=1.2345e9\n",
    "sorted_L_behavioral=np.sort(L)[::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(L))\n",
    "np.sort(L)[::-1]\n",
    "\n",
    "\n",
    "print(np.shape(L))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    rmse, L, sorted_L_behavioral\n",
    "    cullmodels, cullmodels_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** DEFINE (NON)BEHAVIORAL MODELS AND COMPILE STATISTICS **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "behavioral_ids=[]\n",
    "nonbehavioral_ids=[]\n",
    "behavioral_ids_index=[]\n",
    "nonbehavioral_ids_index=[]\n",
    "tempvar=1*(rmse==1.2345e9)\n",
    "\n",
    "for i in np.arange(np.shape(tempvar)[0]):\n",
    "    if tempvar[i]==0:\n",
    "        behavioral_ids.append(runnumbers[i])\n",
    "        behavioral_ids_index.append(i)\n",
    "    else:\n",
    "        nonbehavioral_ids.append(runnumbers[i])\n",
    "        nonbehavioral_ids_index.append(i)\n",
    "\n",
    "holdplotx=[]                                                                                      # store values for later plotting\n",
    "holdploty=[]\n",
    "holdleftlimit=[]\n",
    "holdrightlimit=[]\n",
    "holdplottype=[]\n",
    "\n",
    "num_criteria=0\n",
    "counter=-1\n",
    "\n",
    "if 'in_time_sequence' in locals():\n",
    "    num_criteria=np.shape(in_time_sequence)[0]                                                    # determine number of criteria to that have been applied\n",
    "\n",
    "if num_criteria>0:\n",
    "    for ii in np.arange(num_criteria):                                                            # loop over bases for discrimination of models of concern or (non)behavioral models\n",
    "        in_comparison=in_comparison_sequence[ii]\n",
    "        sorted_in_metric=np.sort(cullmodels[:,ii])[::-1]                                          # sort metric in decreasing order for plotting\n",
    "\n",
    "        # save results to plot later\n",
    "        plottype=0                                                                                # distinguish behavioral (0) and MOC (1) plots\n",
    "        holdplottype.append(plottype)\n",
    "        holdplotx.append(np.arange(np.shape(sorted_in_metric)[0]))                                # store ordinal numbers from 0 to number of models\n",
    "        holdploty.append(sorted_in_metric)                                                        # hold sorted values of the metric used for assessment, high to low\n",
    "        if in_comparison==0:                                                                      # greater than indicates behavioral\n",
    "            holdleftlimit.append(np.shape(behavioral_ids)[0])                                     # limits of behavioral models for sorted plot\n",
    "            holdrightlimit.append(np.shape(sorted_in_metric)[0])\n",
    "        elif in_comparison==1:                                                                    # less than indicates behavioral\n",
    "            holdleftlimit.append(0)\n",
    "            holdrightlimit.append(np.shape(sorted_in_metric)[0]-np.shape(behavioral_ids)[0])\n",
    "   \n",
    "    if np.shape(nonbehavioral_ids)[0]>0:                                                          # assess prevalence of each parameter for in and not-in groups\n",
    "        tempvar=[]\n",
    "        b_meanid=np.zeros(7)\n",
    "        b_varid=np.zeros(7)\n",
    "        for i in np.arange(9,16):                                                                 # count over parameters that are varied in models that exceed max flow\n",
    "            tempvar=np.zeros(len(behavioral_ids_index))                                           # establish array with size equal to number of behavioral models\n",
    "            counter=-1\n",
    "            for j in (behavioral_ids_index):                                                      # count over behavioral models\n",
    "                counter=counter+1\n",
    "                tempvar[counter]= int(runnumbers[j][i])                                           # store digit from model number\n",
    "            b_meanid[i-9]=np.mean(tempvar)                                                        # find mean of each digit\n",
    "            b_varid[i-9]=np.std(tempvar)                                                          # find standard deviation over each digit\n",
    "        tempvar=[]\n",
    "        nonb_meanid=np.zeros(7)\n",
    "        nonb_varid=np.zeros(7)\n",
    "        for i in np.arange(9,16):                                                                 # count over parameters that are varied in models that exceed max flow\n",
    "            tempvar=np.zeros(len(nonbehavioral_ids_index))\n",
    "            counter=-1\n",
    "            for j in (nonbehavioral_ids_index):                                                   # count over models that exceed max flow\n",
    "                counter=counter+1\n",
    "                tempvar[counter]= int(runnumbers[counter][i])                                     # store digit from model number\n",
    "            nonb_meanid[i-9]=np.mean(tempvar)                                                     # find mean of each digit\n",
    "            nonb_varid[i-9]=np.std(tempvar)                                                       # find standard deviation over each digit\n",
    "        nonb_meanid=np.round(nonb_meanid*1000)/1000                                               # truncate for better presentation in table\n",
    "        nonb_varid=np.round(nonb_varid*1000)/1000                \n",
    "    else:\n",
    "        print('All models are behavioral')\n",
    "\n",
    "    del num_criteria                                                                              # clear temporary variables\n",
    "    del tempvar\n",
    "    del counter\n",
    "    del plottype\n",
    "    del sorted_in_metric\n",
    "\n",
    "else:\n",
    "    print('No (non)behavioral criteria listed')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    behavioral_ids, nonbehavioral_ids, behavioral_ids_index, nonbehavioral_ids_index\n",
    "    holdplotx, holdploty, holdleftlimit, holdrightlimit, holdplottype\n",
    "    b_meanid, b_varid, nonb_meanid, nonb_varid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** REMOVE LOW LIKELIHOOD MODELS AND RECALCULATE LIKELIHOODS **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_L=np.sort(L)[::-1]\n",
    "if eliminate_lowL_models==True:\n",
    "    Lcut_ids=np.argsort(L)                                                                        # sort model indices by L, increasing\n",
    "    Lcut_vals=np.sort(L)\n",
    "    numtoremove=int(np.shape(L)[0]*(lowLcut_percent)/100)+np.shape(nonbehavioral_ids)[0]          # find number of models represented by % to remove\n",
    "    checkLlimit=np.sum(Lcut_vals<lowLlimit)                                                       # don't cut models with L above lowLlimit\n",
    "    numtoremove=min(checkLlimit,numtoremove)\n",
    "    numtoremove=min(numtoremove,lowLcut_number)                                                   # don't allow number to remove to pass number limit\n",
    "    Lcut_ids=Lcut_ids[0:numtoremove]     \n",
    "    rmse[Lcut_ids]=1.23456e9\n",
    "    Ltemp=1/rmse                                                                                  # invert rmse as first step to calculating L\n",
    "    \n",
    "#     print(nonbehavioral_ids_index)\n",
    "#     print(Ltemp)\n",
    "#     Ltemp[nonbehavioral_ids_index]=1/1.23456e9\n",
    "#     print(Ltemp)\n",
    "\n",
    "    L=Ltemp/np.sum(Ltemp)\n",
    "\n",
    "    cullmodels_counter=cullmodels_counter+1\n",
    "    cullmodels[:,cullmodels_counter]=L                                                            # store data used to check (non)behavioral status\n",
    "\n",
    "# UNCOMMENT THE FOLLOWING TO DELETE RESULTS RATHER THAN JUST SETTING TO VERY LOW L\n",
    "#     excludemodels1=rmse==1.23456e9\n",
    "#     excludemodels1=1*excludemodels\n",
    "#     excludemodels2=(np.arange(np.shape(runnumbers)[0]))\n",
    "#     excludemodels=excludemodels2[excludemodels1==1]\n",
    "#     for i in np.arange(np.shape(excludemodels)[0]):                                             # delete non-behavioral models\n",
    "#         del runnumbers[excludemodels[i]]\n",
    "#         allheads_ss_ntna = np.delete(allheads_ss_ntna, excludemodels[i],axis=0)                 # remove calculation rows for excluded models\n",
    "#         allheads_ss_ytna = np.delete(allheads_ss_ytna, excludemodels[i],axis=0)\n",
    "#         allheads_ss_ytya = np.delete(allheads_ss_ytya, excludemodels[i],axis=0)\n",
    "#         allflows_ss_ntna = np.delete(allflows_ss_ntna, excludemodels[i],axis=0)\n",
    "#         allflows_ss_ytna = np.delete(allflows_ss_ytna, excludemodels[i],axis=0)\n",
    "#         allflows_ss_ytya = np.delete(allflows_ss_ytya, excludemodels[i],axis=0)\n",
    "#         allleaks_ss_ntna = np.delete(allleaks_ss_ntna, excludemodels[i],axis=0)\n",
    "#         allleaks_ss_ytna = np.delete(allleaks_ss_ytna, excludemodels[i],axis=0)\n",
    "#         allleaks_ss_ytya = np.delete(allleaks_ss_ytya, excludemodels[i],axis=0)\n",
    "#         allepts_ss_ntna = np.delete(allepts_ss_ntna, excludemodels[i],axis=0)            \n",
    "#         dd = np.delete(dd, excludemodels[i],axis=0)     \n",
    "#         run_params = np.delete(run_params, excludemodels[i],axis=0)                             # remove model names from list, too \n",
    "\n",
    "    del numtoremove                                                                                   # clear temporary variables\n",
    "    del checkLlimit\n",
    "    del Ltemp\n",
    "    del Lcut_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    Lcut_ids\n",
    "    rmse, L\n",
    "    cullmodels, cullmodels_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** IDENTIFY MODELS OF CONCERN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to remove nonbehavioral models from MOCs and from other models\n",
    "\n",
    "if run_sections>0:\n",
    "    if define_mocs==True:\n",
    "        moc_total=np.zeros((np.shape(runnumbers)[0]))\n",
    "        num_criteria=np.shape(moc_time_sequence)                                                      # determine number of criteria to apply    \n",
    "        for ii in np.arange(num_criteria[0]):                                                         # loop over bases for discrimination of models of concern or (non)behavioral models\n",
    "            print('Assessing model of concern criterion',ii)\n",
    "            in_time=moc_time_sequence[ii]\n",
    "            in_basis=moc_basis_sequence[ii]\n",
    "            in_comparison=moc_comparison_sequence[ii]\n",
    "            in_limit=moc_limit_sequence[ii]\n",
    "            in_column=moc_column_sequence[ii]\n",
    "            in_row=moc_row_sequence[ii]\n",
    "\n",
    "            if in_basis==0:\n",
    "                in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))\n",
    "                if in_time==0:\n",
    "                    in_metric=np.max(allflows_ss_ntna,axis=1)                                         # store maximum flow for each model for ntna case\n",
    "                elif in_time==1:\n",
    "                    in_metric=np.max(allflows_ss_ytna,axis=1)           \n",
    "                else:\n",
    "                    in_metric=np.max(allflows_ss_ytya,axis=1)           \n",
    "            elif in_basis==1:\n",
    "                in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))     \n",
    "                if in_time==0:\n",
    "                    in_metric=maxdwt_ss_ntna                                                          # store minimum flow for each model for ntna case\n",
    "                elif in_time==1:\n",
    "                    in_metric=maxdwt_ss_ytna                            \n",
    "                else:\n",
    "                    in_metric=in_metric=maxdwt_ss_ytya                  \n",
    "            elif in_basis==2:\n",
    "                in_metric=np.zeros((np.shape(allflows_ss_ntna)[0]))     \n",
    "                if in_time==0:\n",
    "                    for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allflows_ss_ntna[j][in_column]                                   # store flow at specified location for each model for ntna case\n",
    "                elif in_time==1:\n",
    "                    for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allflows_ss_ytna[j][in_column]    \n",
    "                else:\n",
    "                    for j in np.arange(np.shape(allflows_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allflows_ss_ytya[j][in_column]    \n",
    "            elif in_basis==3:\n",
    "                in_metric=np.zeros((np.shape(allheads_ss_ntna)[0]))     \n",
    "                if in_time==0:\n",
    "                    for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allheads_ss_ntna[j][in_row][in_column]                           # store head at specified location for each model for ntna case\n",
    "                elif in_time==1:\n",
    "                    for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allheads_ss_ytna[j][in_row][in_column]    \n",
    "                else:\n",
    "                    for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                        in_metric[j]=allheads_ss_ytya[j][in_row][in_column]    \n",
    "            else:\n",
    "                in_metric=np.zeros((np.shape(dd)[0]))     \n",
    "                if in_time==0:\n",
    "                    for j in np.arange(np.shape(dd)[0]):                \n",
    "                        in_metric[j]=dd[j][in_row][in_column]                                         # store drawdown at specified location for each model for ntna case\n",
    "                elif in_time==1:\n",
    "                    for j in np.arange(np.shape(dd)[0]):                \n",
    "                        in_metric[j]=dd[j][in_row][in_column]    \n",
    "                else:\n",
    "                    for j in np.arange(np.shape(allheads_ss_ytna)[0]):                \n",
    "                        in_metric[j]=dd[j][in_row][in_column]    \n",
    "\n",
    "            cullmodels_counter=cullmodels_counter+1\n",
    "            cullmodels[:,cullmodels_counter]=in_metric                                                # store data used to check (non)behavioral status\n",
    "            cullmodels_counter=cullmodels_counter+1\n",
    "            cullmodels[:,cullmodels_counter]=1*(in_metric>in_limit)                                   # default for in_comparison = 0 ... 1 signifies an MOC, 0 an other model\n",
    "            if in_comparison==1:\n",
    "                cullmodels[:,cullmodels_counter]=1-cullmodels[:,cullmodels_counter]\n",
    "            moc_total=moc_total+cullmodels[:,cullmodels_counter]    \n",
    "            nummocs=np.sum(cullmodels[:,cullmodels_counter])\n",
    "\n",
    "            sorted_in_metric=np.sort(in_metric)[::-1]                                                 # sort metric in decreasing order over all models\n",
    "\n",
    "            # save results to plot later\n",
    "            plottype=1\n",
    "            holdplottype.append(plottype)\n",
    "            holdplotx.append(np.arange(np.shape(runnumbers)[0]))                                      # store ordinal numbers from 0 to number of criteria used for assessing models\n",
    "            holdploty.append(sorted_in_metric)                                                        # hold sorted values of the metric used for assessment, high to low\n",
    "            if in_comparison==0:                                                                      # greater than indicates behavioral\n",
    "                holdleftlimit.append(nummocs)                                                         # model zero presumably behavioral\n",
    "                holdrightlimit.append(np.shape(runnumbers)[0])\n",
    "            elif in_comparison==1:\n",
    "                holdleftlimit.append(0)\n",
    "                holdrightlimit.append(np.shape(runnumbers)[0]-nummocs)\n",
    "\n",
    "        cullmodels_counter=cullmodels_counter+1\n",
    "        cullmodels[:,cullmodels_counter]=moc_total\n",
    "        np.savetxt(\"cullmodels.csv\", cullmodels, delimiter=\",\")                                       # output this file to check all analyses to this point manually\n",
    "\n",
    "        moc_ids=[]\n",
    "        other_ids=[]\n",
    "        moc_ids_counter=[]\n",
    "        other_ids_counter=[]\n",
    "        for i in np.arange(np.shape(runnumbers)[0]):                                                  # loop over all models\n",
    "            if moc_total[i]>0:\n",
    "                moc_ids.append(runnumbers[i])\n",
    "                moc_ids_counter.append(i)\n",
    "            else:\n",
    "                other_ids.append(runnumbers[i])                                                       # store names of other models\n",
    "                other_ids_counter.append(i)\n",
    "\n",
    "        moc_ids=[x for x in moc_ids if not x in nonbehavioral_ids]\n",
    "        other_ids=[x for x in other_ids if not x in nonbehavioral_ids]\n",
    "\n",
    "        if np.shape(moc_ids)[0]>0:                                                                  # Assess prevalence of each parameter on in and not-in groups\n",
    "            tempvar=[]\n",
    "            moc_meanid=np.zeros(7)\n",
    "            moc_varid=np.zeros(7)\n",
    "            for i in np.arange(9,16):                                                                 # count over parameters that are varied in models that exceed max flow\n",
    "                tempvar=np.zeros(len(moc_ids))\n",
    "                counter=-1\n",
    "                for j in (moc_ids):                                                                   # count over models that exceed max flow\n",
    "                    counter=counter+1\n",
    "                    tempvar[counter]= int(runnumbers[counter][i])                                     # store digit from model number\n",
    "                moc_meanid[i-9]=np.mean(tempvar)                                                      # find mean of each digit\n",
    "                moc_varid[i-9]=np.std(tempvar)                                                        # find standard deviation over each digit\n",
    "            moc_meanid=np.round(moc_meanid*1000)/1000\n",
    "            tempvar=[]\n",
    "            other_meanid=np.zeros(7)\n",
    "            other_varid=np.zeros(7)\n",
    "            for i in np.arange(9,16):                                                                 # count over parameters that are varied in models that exceed max flow\n",
    "                tempvar=np.zeros(len(other_ids))\n",
    "                counter=-1\n",
    "                for j in (other_ids):                                                                 # count over models that exceed max flow\n",
    "                    counter=counter+1\n",
    "                    tempvar[counter]= int(runnumbers[counter][i])                                     # store digit from model number\n",
    "                other_meanid[i-9]=np.mean(tempvar)                                                    # find mean of each digit\n",
    "                other_varid[i-9]=np.std(tempvar)                                                      # find standard deviation over each digit\n",
    "            other_meanid=np.round(other_meanid*1000)/1000\n",
    "        else:\n",
    "            print('No models of concern')\n",
    "\n",
    "    if 'tempvar' in locals():\n",
    "        del tempvar                                                                                       # clear temporary variables\n",
    "        del counter\n",
    "    del in_metric\n",
    "    del in_time\n",
    "    del in_basis\n",
    "    del in_comparison\n",
    "    del in_limit\n",
    "    del in_column\n",
    "    del in_row\n",
    "    del num_criteria\n",
    "\n",
    "    #Export files needed for multi-stakeholder comparisons:\n",
    "    #To import, use np.load()\n",
    "    comparison_directory()               #change directory to current stakeholder and stage\n",
    "    np.save(prefix + 'runnumbers', runnumbers)\n",
    "    np.save(prefix +'sorted_L', sorted_L)\n",
    "    np.save(prefix +'L', L)\n",
    "    np.save(prefix +'moc_ids_counter', moc_ids_counter)\n",
    "    output_directory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    moc_total, nummocs\n",
    "        \n",
    "    sorted_in_metric\n",
    "    holdplotx, holdploty, holdleftlimit, holdrightlimit, holdplottype\n",
    "    \n",
    "    b_meanid, b_varid, nonb_meanid, nonb_varid\n",
    "    moc_ids, other_ids, moc_ids_counter, other_ids_counter\n",
    "    moc_meanid, moc_varid, other_meanid, other_varid\n",
    "    \n",
    "    rmse, L\n",
    "    cullmodels, cullmodels_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATE LIKELIHOOD-WEIGHTED MEAN AND STANDARD DEVIATION OVER ENSEMBLE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_sections>-1:\n",
    "    def Lstats(Lin,datain):                                                                           # this function calculates the likelihood weighted mean and standard deviation, defaults to normal mean and std if no data available\n",
    "        tempout=[]\n",
    "        if np.ndim(datain)==3:                                                                        # used to differentiate head and stream data by dimensionality\n",
    "            tempmeanmatrix=np.zeros((np.shape(datain)[1],np.shape(datain)[2]))                        # set up array to store mean over all data\n",
    "            tempstdmatrix=np.zeros((np.shape(datain)[1],np.shape(datain)[2]))                         # set up array to store standard deviation over all data\n",
    "        elif np.ndim(datain)==2:\n",
    "            tempmeanmatrix=np.zeros((np.shape(datain)[1]))\n",
    "            tempstdmatrix=np.zeros((np.shape(datain)[1]))\n",
    "        else:                                                                                         # kill the program if the data has neither 2 nor 3 dimensions\n",
    "            print('problem with an input file')\n",
    "            die\n",
    "        for j in np.arange(np.shape(datain)[1]):\n",
    "            if np.ndim(datain)==3:                                                                    # treat 2 and 3 dimensional data differently\n",
    "                for k in np.arange(np.shape(datain)[2]):\n",
    "                    tempvar=datain[:,j,k]\n",
    "                    tempmeanval=np.sum(tempvar*Lin)/np.sum(Lin)                                       # calculate L-weighted mean over all models at each location\n",
    "                    tempmeanmatrix[j,k]=tempmeanval\n",
    "                    meanremove=np.repeat(tempmeanval,np.shape(tempvar)[0])\n",
    "                    tempstdmatrix[j,k]=(np.sum(Lin*(tempvar-meanremove)**2)/(np.sum(Lin)*\n",
    "                        (np.shape(Lin)[0]-1)/np.shape(Lin)[0]))**0.5                                  # calculate L-weighted standard deviation over all models at each location\n",
    "            else:\n",
    "                tempvar=datain[:,j]\n",
    "                tempmeanval=np.sum(tempvar*Lin)/np.sum(Lin)\n",
    "                tempmeanmatrix[j]=tempmeanval\n",
    "                meanremove=np.repeat(tempmeanval,np.shape(tempvar)[0])\n",
    "                tempstdmatrix[j]=(np.sum(Lin*(tempvar-meanremove)**2)/(np.sum(Lin)*\n",
    "                     (np.shape(Lin)[0]-1)/np.shape(Lin)[0]))**0.5\n",
    "        tempout.append(tempmeanmatrix)                                                                # export matrix of L-weighted means over all models at each point\n",
    "        tempout.append(tempstdmatrix)                                                                 # export matrix of L-weighted standard deviations over all models at each point\n",
    "        del tempmeanval                                                                               # clear temporary variables\n",
    "        del meanremove\n",
    "        del tempvar\n",
    "        del tempmeanmatrix\n",
    "        del tempstdmatrix\n",
    "        return tempout\n",
    "\n",
    "\n",
    "    bestmodels=np.argsort(-L)\n",
    "    MLmodelID=bestmodels[0]\n",
    "\n",
    "    # remember to add calculations for budget elements\n",
    "    tempout=Lstats(L,allheads_ss_ntna)                                                                # call the function to calculate the L weighted mean and std\n",
    "    headmean_ss_ntna=tempout[0]                                                                       # store the mean\n",
    "    headvar_ss_ntna=tempout[1]                                                                        # store the standard deviation\n",
    "    headML_ss_ntna=allheads_ss_ntna[bestmodels[0]]\n",
    "    tempout=Lstats(L,allheads_ss_ytna)\n",
    "    headmean_ss_ytna=tempout[0]\n",
    "    headML_ss_ytna=allheads_ss_ytna[bestmodels[0]]\n",
    "    headvar_ss_ytna=tempout[1]\n",
    "    tempout=Lstats(L,allheads_ss_ytya)\n",
    "    headmean_ss_ytya=tempout[0]\n",
    "    headML_ss_ytya=allheads_ss_ytya[bestmodels[0]]\n",
    "    headvar_ss_ytya=tempout[1]\n",
    "    tempout=Lstats(L,dd)\n",
    "    ddmean=tempout[0]\n",
    "    ddvar=tempout[1]\n",
    "    tempout=Lstats(L,allleaks_ss_ntna)\n",
    "    leakmean_ss_ntna=tempout[0]\n",
    "    leakvar_ss_ntna=tempout[1]\n",
    "    tempout=Lstats(L,allleaks_ss_ytna)\n",
    "    leakmean_ss_ytna=tempout[0]\n",
    "    leakvar_ss_ytna=tempout[1]\n",
    "    tempout=Lstats(L,allleaks_ss_ytya)\n",
    "    leakmean_ss_ytya=tempout[0]\n",
    "    leakvar_ss_ytya=tempout[1]\n",
    "    tempout=Lstats(L,allflows_ss_ntna)\n",
    "    flowmean_ss_ntna=tempout[0]\n",
    "    flowML_ss_ntna=allflows_ss_ntna[bestmodels[0]]\n",
    "    flowvar_ss_ntna=tempout[1]\n",
    "    tempout=Lstats(L,allflows_ss_ytna)\n",
    "    flowmean_ss_ytna=tempout[0]\n",
    "    flowML_ss_ytna=allflows_ss_ytna[bestmodels[0]]\n",
    "    flowvar_ss_ytna=tempout[1]\n",
    "    tempout=Lstats(L,allflows_ss_ytya)\n",
    "    flowmean_ss_ytya=tempout[0]\n",
    "    flowML_ss_ytya=allflows_ss_ytya[bestmodels[0]]\n",
    "    flowvar_ss_ytya=tempout[1]\n",
    "\n",
    "if run_sections>0:\n",
    "    # calculate L-weighted stats for MOCs and other models, if defined\n",
    "    if define_mocs==True and np.shape(moc_ids_counter)[0] > 0:\n",
    "        tempout=Lstats(L[moc_ids_counter],allheads_ss_ntna[moc_ids_counter])\n",
    "        moc_headmean_ss_ntna=tempout[0]\n",
    "        moc_headvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allheads_ss_ytna[moc_ids_counter])\n",
    "        moc_headmean_ss_ytna=tempout[0]\n",
    "        moc_headvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allheads_ss_ytya[moc_ids_counter])\n",
    "        moc_headmean_ss_ytya=tempout[0]\n",
    "        moc_headvar_ss_ytya=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allleaks_ss_ntna[moc_ids_counter])\n",
    "        moc_leakmean_ss_ntna=tempout[0]\n",
    "        moc_leakvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allleaks_ss_ytna[moc_ids_counter])\n",
    "        moc_leakmean_ss_ytna=tempout[0]\n",
    "        moc_leakvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allleaks_ss_ytya[moc_ids_counter])\n",
    "        moc_leakmean_ss_ytya=tempout[0]\n",
    "        moc_leakvar_ss_ytya=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allflows_ss_ntna[moc_ids_counter])\n",
    "        moc_flowmean_ss_ntna=tempout[0]\n",
    "        moc_flowvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allflows_ss_ytna[moc_ids_counter])\n",
    "        moc_flowmean_ss_ytna=tempout[0]\n",
    "        moc_flowvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[moc_ids_counter],allflows_ss_ytya[moc_ids_counter])\n",
    "        moc_flowmean_ss_ytya=tempout[0]\n",
    "        moc_flowvar_ss_ytya=tempout[1]\n",
    "\n",
    "        tempout=Lstats(L[other_ids_counter],allheads_ss_ntna[other_ids_counter])\n",
    "        other_headmean_ss_ntna=tempout[0]\n",
    "        other_headvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allheads_ss_ytna[other_ids_counter])\n",
    "        other_headmean_ss_ytna=tempout[0]\n",
    "        other_headvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allheads_ss_ytya[other_ids_counter])\n",
    "        other_headmean_ss_ytya=tempout[0]\n",
    "        other_headvar_ss_ytya=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allleaks_ss_ntna[other_ids_counter])\n",
    "        other_leakmean_ss_ntna=tempout[0]\n",
    "        other_leakvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allleaks_ss_ytna[other_ids_counter])\n",
    "        other_leakmean_ss_ytna=tempout[0]\n",
    "        other_leakvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allleaks_ss_ytya[other_ids_counter])\n",
    "        other_leakmean_ss_ytya=tempout[0]\n",
    "        other_leakvar_ss_ytya=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allflows_ss_ntna[other_ids_counter])\n",
    "        other_flowmean_ss_ntna=tempout[0]\n",
    "        other_flowvar_ss_ntna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allflows_ss_ytna[other_ids_counter])\n",
    "        other_flowmean_ss_ytna=tempout[0]\n",
    "        other_flowvar_ss_ytna=tempout[1]\n",
    "        tempout=Lstats(L[other_ids_counter],allflows_ss_ytya[other_ids_counter])\n",
    "        other_flowmean_ss_ytya=tempout[0]\n",
    "        other_flowvar_ss_ytya=tempout[1]\n",
    "\n",
    "    del tempout                                                                                       # clear temporary variables\n",
    "    del bestmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    headmean_ss_ntna, headmean_ss_ytna, headmean_ss_ytya\n",
    "    headvar_ss_ntna, headvar_ss_ytna, headvar_ss_ytya\n",
    "    leakmean_ss_ntna, leakmean_ss_ytna, leakmean_ss_ytya\n",
    "    leakvar_ss_ntna, leakvar_ss_ytna, leakvar_ss_ytya\n",
    "    flowmean_ss_ntna, flowmean_ss_ytna, flowmean_ss_ytya\n",
    "    flowvar_ss_ntna, flowvar_ss_ytna, flowvar_ss_ytya\n",
    "    \n",
    "    dd_mean, dd_var\n",
    "        \n",
    "    moc_headmean_ss_ntna, moc_headmean_ss_ytna, moc_headmean_ss_ytya\n",
    "    moc_headvar_ss_ntna, moc_headvar_ss_ytna, moc_headvar_ss_ytya\n",
    "    moc_leakmean_ss_ntna, moc_leakmean_ss_ytna, moc_leakmean_ss_ytya\n",
    "    moc_leakvar_ss_ntna, moc_leakvar_ss_ytna, moc_leakvar_ss_ytya\n",
    "    moc_flowmean_ss_ntna, moc_flowmean_ss_ytna, moc_flowmean_ss_ytya\n",
    "    moc_flowvar_ss_ntna, moc_flowvar_ss_ytna, moc_flowvar_ss_ytya\n",
    "\n",
    "    other_headmean_ss_ntna, other_headmean_ss_ytna, other_headmean_ss_ytya\n",
    "    other_headvar_ss_ntna, other_headvar_ss_ytna, other_headvar_ss_ytya\n",
    "    other_leakmean_ss_ntna, other_leakmean_ss_ytna, other_leakmean_ss_ytya\n",
    "    other_leakvar_ss_ntna, other_leakvar_ss_ytna, other_leakvar_ss_ytya\n",
    "    other_flowmean_ss_ntna, other_flowmean_ss_ytna, other_flowmean_ss_ytya\n",
    "    other_flowvar_ss_ntna, other_flowvar_ss_ytna, other_flowvar_ss_ytya\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATE OVERLAP OF MOCs AND OTHER MODELS AT EACH LOCATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  if run_sections>1:\n",
    "    moc_L=L[moc_ids_counter]                                                                                           # likelihoods of MOCs only\n",
    "    other_L=L[other_ids_counter]                                                                                       # likelihoods of other models only\n",
    "\n",
    "    for k in np.arange(3):                                                                                             # find overlap for heads\n",
    "        overlap=np.zeros((np.shape(allheads_ss_ntna)[1],np.shape(allheads_ss_ntna)[2]))\n",
    "        if k==0:\n",
    "            data=allheads_ss_ntna\n",
    "        elif k==1:\n",
    "            data=allheads_ss_ytna\n",
    "        else:\n",
    "            data=allheads_ss_ytya\n",
    "        moc_data=data[moc_ids_counter]\n",
    "        other_data=data[other_ids_counter]\n",
    "\n",
    "        for i in np.arange(np.shape(allheads_ss_ntna)[1]):                                                             # loop over both horizontal dimensions\n",
    "            for j in np.arange(np.shape(allheads_ss_ntna)[2]):\n",
    "                mocmask=np.zeros(np.shape(moc_data)[0])                                                                # initialize arrays for MOCs and other models\n",
    "                othermask=np.zeros(np.shape(other_data)[0])\n",
    "                maxcutoff=min(max(moc_data[:,i,j]),max(other_data[:,i,j]))                                             # find lower maximum value between all MOCs and all other models    \n",
    "                mincutoff=max(min(moc_data[:,i,j]),min(other_data[:,i,j]))                                             # find higher minimum value between all MOCs and all other models \n",
    "                mocmask=1-(1*(moc_data[:,i,j]>maxcutoff)+1*(moc_data[:,i,j]<mincutoff))                                # find MOCs with predictions WITHIN overlap\n",
    "                othermask=1-(1*(other_data[:,i,j]>maxcutoff)+1*(other_data[:,i,j]<mincutoff))                          # find other models with predictions WITHIN overlap\n",
    "                overlap[i,j]=np.sum(moc_L*mocmask)+np.sum(other_L*othermask)                                           # sum likelihoods of models in overlap\n",
    "                overlap[overlap==1]=np.nan                                                                             # an overlap of 1 generally occurs because all models give the same value - a fixed head boundary or a cut out corner\n",
    "\n",
    "        if k==0:\n",
    "            overlap_ntna_head=overlap\n",
    "        elif k==1:\n",
    "            overlap_ytna_head=overlap\n",
    "        else:\n",
    "            overlap_ytya_head=overlap\n",
    "\n",
    "    for k in np.arange(3):                                                                                             # find overlap for flows\n",
    "        overlap=np.zeros((np.shape(allheads_ss_ntna)[1]))\n",
    "        if k==0:\n",
    "            data=allflows_ss_ntna\n",
    "        elif k==1:\n",
    "            data=allflows_ss_ytna\n",
    "        else:\n",
    "            data=allflows_ss_ytya\n",
    "        moc_data=data[moc_ids_counter]\n",
    "        other_data=data[other_ids_counter]\n",
    "\n",
    "        for i in np.arange(np.shape(allflows_ss_ntna)[1]):                                                             # loop over both horizontal dimensions\n",
    "            mocmask=np.zeros(np.shape(moc_data)[0])                                                                    # initialize arrays for MOCs and other models\n",
    "            othermask=np.zeros(np.shape(other_data)[0])\n",
    "            maxcutoff=min(max(moc_data[:,i]),max(other_data[:,i]))                                                     # find lower maximum value between all MOCs and all other models    \n",
    "            mincutoff=max(min(moc_data[:,i]),min(other_data[:,i]))                                                     # find higher minimum value between all MOCs and all other models \n",
    "            mocmask=1-(1*(moc_data[:,i]>=maxcutoff)+1*(moc_data[:,i]<=mincutoff))                                      # find MOCs with predictions WITHIN overlap\n",
    "            othermask=1-(1*(other_data[:,i]>=maxcutoff)+1*(other_data[:,i]<=mincutoff))                                                 # find other models with predictions WITHIN overlap\n",
    "            overlap[i]=np.sum(moc_L*mocmask)+np.sum(other_L*othermask)                                                                                   # sum likelihoods of models in overlap\n",
    "        if k==0:\n",
    "            overlap_ntna_flow=overlap[1:49]\n",
    "        elif k==1:\n",
    "            overlap_ytna_flow=overlap[1:49]\n",
    "        else:\n",
    "            overlap_ytya_flow=overlap[1:49]\n",
    "\n",
    "    for k in np.arange(3):                                                                                             # find overlap for leakages\n",
    "        overlap=np.zeros((np.shape(allheads_ss_ntna)[1]))\n",
    "        if k==0:\n",
    "            data=allleaks_ss_ntna\n",
    "        elif k==1:\n",
    "            data=allleaks_ss_ytna\n",
    "        else:\n",
    "            data=allleaks_ss_ytya\n",
    "        moc_data=data[moc_ids_counter]\n",
    "        other_data=data[other_ids_counter]\n",
    "\n",
    "        for i in np.arange(np.shape(allleaks_ss_ntna)[1]):                                                             # loop over both horizontal dimensions\n",
    "            mocmask=np.zeros(np.shape(moc_data)[0])                                                                    # initialize arrays for MOCs and other models\n",
    "            othermask=np.zeros(np.shape(other_data)[0])\n",
    "            maxcutoff=min(max(moc_data[:,i]),max(other_data[:,i]))                                                     # find lower maximum value between all MOCs and all other models    \n",
    "            mincutoff=max(min(moc_data[:,i]),min(other_data[:,i]))                                                     # find higher minimum value between all MOCs and all other models \n",
    "            mocmask=1-(1*(moc_data[:,i]>=maxcutoff)+1*(moc_data[:,i]<=mincutoff))                                      # find MOCs with predictions WITHIN overlap\n",
    "            othermask=1-(1*(other_data[:,i]>=maxcutoff)+1*(other_data[:,i]<=mincutoff))                                                 # find other models with predictions WITHIN overlap\n",
    "            overlap[i]=np.sum(moc_L*mocmask)+np.sum(other_L*othermask)                                                 # sum likelihoods of models in overlap\n",
    "        if k==0:\n",
    "            overlap_ntna_leak=overlap[1:49]     # not sure why, but this crashes in plots if not fixed like this ... WHY??\n",
    "            overlap_ntna_leak=overlap\n",
    "        elif k==1:\n",
    "            overlap_ytna_leak=overlap[1:49]\n",
    "        else:\n",
    "            overlap_ytya_leak=overlap[1:49]\n",
    "\n",
    "    del overlap                                                                                                        # clear temporary variables\n",
    "    del mocmask\n",
    "    del othermask\n",
    "    del maxcutoff\n",
    "    del mincutoff\n",
    "    del moc_data\n",
    "    del other_data\n",
    "    del moc_L\n",
    "    del other_L\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    overlap_ntna_head, overlap_ytna_head, overlap_ytya_head\n",
    "    overlap_ntna_flow, overlap_ytna_flow, overlap_ytya_flow\n",
    "    overlap_ntna_leak, overlap_ytna_leak, overlap_ytya_leak\n",
    "    moc_L, other_L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATE DISCRIMINATORY INDEX AT EACH LOCATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_sections>1:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        meandiff_ntna=np.abs(other_headmean_ss_ntna-moc_headmean_ss_ntna)\n",
    "        meandiff_ytna=np.abs(other_headmean_ss_ytna-moc_headmean_ss_ytna)\n",
    "        meandiff_ytya=np.abs(other_headmean_ss_ytya-moc_headmean_ss_ytya)\n",
    "        sumvar_ntna=other_headvar_ss_ntna+moc_headvar_ss_ntna\n",
    "        sumvar_ntna[sumvar_ntna<1e-10]=np.nan\n",
    "        sumvar_ytna=other_headvar_ss_ytna+moc_headvar_ss_ytna\n",
    "        sumvar_ytna[sumvar_ytna<1e-10]=np.nan\n",
    "        sumvar_ytya=other_headvar_ss_ytya+moc_headvar_ss_ytya\n",
    "        sumvar_ytya[sumvar_ytya<1e-10]=np.nan\n",
    "        di_std_ntna=meandiff_ntna/sumvar_ntna\n",
    "        di_std_ytna=meandiff_ytna/sumvar_ytna\n",
    "        di_std_ytya=meandiff_ytya/sumvar_ytya\n",
    "        di_overlap_ntna=np.abs(meandiff_ntna)*(1-overlap_ntna_head)\n",
    "        di_overlap_ytna=np.abs(meandiff_ytna)*(1-overlap_ytna_head)\n",
    "        di_overlap_ytya=np.abs(meandiff_ytya)*(1-overlap_ytya_head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    meandiff_ntna, meandiff_ytna, meandiff_ytya\n",
    "    sumvar_ntna, sumvar_ytna, sumvar_ytya\n",
    "    di_std_ntna, di_std_ytna, di_std_ytya\n",
    "    di_overlap_ntna, di_overlap_ytna, di_overlap_ytya\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CALCULATE PARTICLE CAPTURE BY TOWN WELL, AG WELL, AND STREAM FOR EACH STARTING LOCATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_sections>2:\n",
    "    # find highest L model\n",
    "    maxLid=np.argsort(-L)[0]\n",
    "\n",
    "    strcapgrid=np.zeros((3,nrow,ncol))                                                                # initiate array to store starting locations of particles that end in stream\n",
    "    w1capgrid=np.zeros((3,nrow,ncol))                                                                 # initiate array to store starting locations of particles that end in town well\n",
    "    w2capgrid=np.zeros((3,nrow,ncol))                                                                 # initiate array to store starting locations of particles that end in ag well\n",
    "    maxLw1capgrid=np.zeros((3,nrow,ncol))\n",
    "    farmcappermodel=np.zeros(np.shape(runnumbers))\n",
    "    streamcappermodel=np.zeros(np.shape(runnumbers))\n",
    "    for k in np.arange(3):                                                                            # loop over ntna, ytna, ytya\n",
    "        for i in np.arange(np.shape(runnumbers)[0]):                                                  # loop over all models in ensemble                 \n",
    "            for j in np.arange(np.shape(allepts_ss_ntna)[1]):                                         # loop over all particles\n",
    "                if k==0:\n",
    "                    exloc=int(allepts_ss_ntna[i,j,3])                                                 # ending column   \n",
    "                    eyloc=int(allepts_ss_ntna[i,j,2])                                                 # ending row\n",
    "                    sxloc=int(allepts_ss_ntna[i,j,1])                                                 # starting column\n",
    "                    syloc=int(allepts_ss_ntna[i,j,0])                                                 # starting row\n",
    "                elif k==1:\n",
    "                    exloc=int(allepts_ss_ytna[i,j,3])\n",
    "                    eyloc=int(allepts_ss_ytna[i,j,2])\n",
    "                    sxloc=int(allepts_ss_ytna[i,j,1])\n",
    "                    syloc=int(allepts_ss_ytna[i,j,0])\n",
    "                else:\n",
    "                    exloc=int(allepts_ss_ytya[i,j,3])\n",
    "                    eyloc=int(allepts_ss_ytya[i,j,2])\n",
    "                    sxloc=int(allepts_ss_ytya[i,j,1])\n",
    "                    syloc=int(allepts_ss_ytya[i,j,0])\n",
    "                if exloc==well1[1] and eyloc==well1[2]:                                               # identify particles that end in well1\n",
    "                    # add code to determine how many farm particles town well captures for each model                    \n",
    "                    if k==2 and sxloc>=fNWc[1] and sxloc<=fNWc[1] +1:                                 # determine if sxloc and syloc for this particle originate on farm, layer 0                        \n",
    "                        if syloc>=fNWc[0] and syloc<=fNWc[0] +1:\n",
    "                            farmcappermodel[i]=farmcappermodel[i]+1                                   # if so, add one to tally for this model\n",
    "                    w1capgrid[k,sxloc,syloc]=w1capgrid[k,sxloc,syloc]+L[i]                            # tally likelihood of model associated with particles captured from each grid cell over all models\n",
    "                    if k==2 and i==maxLid:\n",
    "                        maxLw1capgrid[k,sxloc,syloc]=1\n",
    "                if exloc==well2[1] and eyloc==well2[2]:      \n",
    "                    w2capgrid[k,sxloc,syloc]=w2capgrid[k,sxloc,syloc]+L[i]     \n",
    "                if exloc==strrow:     \n",
    "                    strcapgrid[k,sxloc,syloc]=strcapgrid[k,sxloc,syloc]+L[i]     \n",
    "                    if k==2 and sxloc>=fNWc[1] and sxloc<=fNWc[1] +1:                                 # determine if sxloc and syloc for this particle originate on farm, layer 0                        \n",
    "                        if syloc>=fNWc[0] and syloc<=fNWc[0] +1:\n",
    "                            streamcappermodel[i]=streamcappermodel[i]+1                                   # if so, add one to tally for this model\n",
    "\n",
    "    del exloc                                                                                         # clear temporary variables\n",
    "    del eyloc\n",
    "    del sxloc\n",
    "    del syloc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carried over variables\n",
    "\n",
    "    strcapgrid, w1capgrid, w2capgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPORT LIKELIHOODS**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export files needed for multi-stakeholder comparisons:\n",
    "#To import, use np.load()\n",
    "# comparison_directory()               #change directory to current stakeholder and stage\n",
    "# np.save(prefix + 'runnumbers', runnumbers)\n",
    "# np.save(prefix +'sorted_L', sorted_L)\n",
    "# np.save(prefix +'L', L)\n",
    "# np.save(prefix +'moc_ids_counter', moc_ids_counter)\n",
    "# output_directory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATE REPORTS**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The final ensemble includes ',np.shape(runnumbers)[0],' models')\n",
    "print()\n",
    "\n",
    "if np.shape(nonbehavioral_ids)[0]>0:\n",
    "    print('There were ', np.shape(nonbehavioral_ids)[0],'non-behavioral models.')\n",
    "    print()\n",
    "    print('Non-behavioral models:')\n",
    "    for i in np.arange(np.shape(nonbehavioral_ids)[0]):\n",
    "        print(nonbehavioral_ids[i])\n",
    "    print()\n",
    "    print('There were ', np.shape(Lcut_ids)[0],'low likelihood models.')\n",
    "    if np.shape(Lcut_ids)[0]>0 and lowLecho==True:\n",
    "        print()\n",
    "        print('Low-likelihood models:')\n",
    "        for i in Lcut_ids:\n",
    "            print(runnumbers[i])\n",
    "    print()\n",
    "print('Assessing prevalence of each parameter for behavioral and non-behavioral models')\n",
    "print()\n",
    "print('                                       Ky    low Kz   Sy    Rm      ETv     ETr   Kstr')\n",
    "print()\n",
    "print('Behavioral average ----------------',np.floor(b_meanid*1000)/1000)\n",
    "print('Behavioral deviation --------------',np.floor(b_varid*1000)/1000)\n",
    "print()\n",
    "plottitle='(Non)behavioral criterion'\n",
    "if np.shape(nonbehavioral_ids)[0]>0:\n",
    "    print('Non-behavioral average ------------',np.floor(nonb_meanid*1000)/1000)\n",
    "    print('Non-behavioral standard deviation -',np.floor(nonb_varid*1000)/1000)\n",
    "    print()\n",
    "    for ij in np.arange(np.shape(holdplotx)[0]):\n",
    "        if holdplottype[ij]==0:\n",
    "            f0,ax1 = plt.subplots(1,1,figsize=(20,4))                                             # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "            tempplotx=holdplotx[ij][:]\n",
    "            tempploty=holdploty[ij][:]\n",
    "            c = ax1.plot(tempplotx,tempploty,color=\"blue\",label='behavioral')     \n",
    "            tempplotx=tempplotx[holdleftlimit[ij]:holdrightlimit[ij]]\n",
    "            tempploty=tempploty[holdleftlimit[ij]:holdrightlimit[ij]]\n",
    "            c = ax1.plot(tempplotx,tempploty,color=\"red\",label='nonbehavioral')     \n",
    "            ax1.set_xlabel('model instance - sorted, not model number')\n",
    "            ax1.set_ylabel('value of metric used to define in-group models')\n",
    "            ax1.legend()\n",
    "            plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "            plt.show(f0)   \n",
    "        else:\n",
    "            skipprint=1\n",
    "\n",
    "else:\n",
    "    print('All models are behavioral')\n",
    "\n",
    "if run_sections>0:\n",
    "    if np.shape(moc_ids)[0]>0:\n",
    "        print('There were ', np.shape(moc_ids)[0],'models of concern.')\n",
    "        print()\n",
    "        print('Models of concern:')\n",
    "        for i in np.arange(np.shape(moc_ids)[0]):\n",
    "            print(moc_ids[i])\n",
    "        print()\n",
    "\n",
    "    print('Assessing prevalence of each parameter for models of concern and other models')\n",
    "    print()\n",
    "    print('                                              Ky    low Kz   Sy    Rm      ETv     ETr   Kstr')\n",
    "    print()\n",
    "    print('Models of concern average ----------------',np.floor(moc_meanid*1000)/1000)\n",
    "    print('Models of concern standard deviation -----',np.floor(moc_varid*1000)/1000)\n",
    "    print()\n",
    "    plottitle='Model of concern criterion'\n",
    "    if np.shape(moc_ids)[0]>0:\n",
    "        print('Other model average ----------------------',np.floor(other_meanid*1000)/1000)\n",
    "        print('Other model standard deviation -----------',np.floor(other_varid*1000)/1000)\n",
    "        print()\n",
    "        moccounter=-1\n",
    "        for ij in np.arange(np.shape(holdplotx)[0]):\n",
    "            if holdplottype[ij]==1:\n",
    "                moccounter=moccounter+1\n",
    "                f1,ax1 = plt.subplots(1,1,figsize=(20,4))                                             # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "                tempplotx=holdplotx[ij][:]\n",
    "                tempploty=holdploty[ij][:]\n",
    "                c = ax1.plot(tempplotx,tempploty,color=\"red\",label='models of concern')     \n",
    "                tempplotx=tempplotx[int(holdleftlimit[ij]):int(holdrightlimit[ij])]\n",
    "                tempploty=tempploty[int(holdleftlimit[ij]):int(holdrightlimit[ij])]\n",
    "                c = ax1.plot(tempplotx,tempploty,color=\"blue\",label='other models')     \n",
    "                ax1.set_xlabel('model instance - sorted, not model number')\n",
    "                ax1.set_ylabel('value of metric used to define in-group models')\n",
    "                plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "                ax1.legend()\n",
    "                plt.show(f1)     \n",
    "            else:\n",
    "                skipprint=1\n",
    "    else:\n",
    "        print('There are no models of concern')\n",
    "\n",
    "    plottitle='Model Likelihoods'\n",
    "    f2,ax1 = plt.subplots(1,1,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    xplot=np.arange(len(runnumbers))                                                                  # plot sorted streamflows against number of runs\n",
    "    c = ax1.plot(xplot,sorted_L,'*',label='other models')   \n",
    "    tempvar=np.argsort(-L)\n",
    "    xplot=np.zeros(np.shape(moc_ids_counter)[0])\n",
    "    yplot=np.zeros(np.shape(moc_ids_counter)[0])\n",
    "    count=-1\n",
    "    Lsum_moc=0\n",
    "    for i in np.arange(np.shape(tempvar)[0]):  \n",
    "        if np.shape(np.intersect1d(tempvar[i],moc_ids_counter))[0]>0:\n",
    "            count=count+1\n",
    "            xplot[count]=(i)\n",
    "            yplot[count]=(L[tempvar[i]])\n",
    "            Lsum_moc=Lsum_moc+L[tempvar[i]]                                                           # keep track of total L in MOCs\n",
    "    c = ax1.plot(xplot,yplot,'*',color=\"Red\",label='models of concern')   \n",
    "    ax1.set_xlabel('model instance - sorted, not model number')\n",
    "    ax1.set_ylabel('Likelihood')\n",
    "    plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "    ax1.legend()\n",
    "    plt.show(f2)     \n",
    "\n",
    "    print('Models with highest likelihoods')\n",
    "    print()\n",
    "    bestmodels=np.argsort(-L)\n",
    "    numbest=np.shape(bestmodels)[0]\n",
    "    if numbest>10:\n",
    "        numbest=10\n",
    "\n",
    "    for i in range(numbest):\n",
    "        if runnumbers[bestmodels[i]] in moc_ids:\n",
    "            print(runnumbers[i],' L =', np.floor(L[bestmodels[i]]*1000)/1000, 'model of concern')\n",
    "        else:\n",
    "            print(runnumbers[i],' L =', np.floor(L[bestmodels[i]]*1000)/1000, 'other model')\n",
    "\n",
    "    print()\n",
    "    print('The total likelihood of the models of concern is ',np.floor(Lsum_moc*1000)/1000)\n",
    "\n",
    "    del plottitle                                                                                     # clear temporary variables\n",
    "    del tempplotx\n",
    "    del tempploty\n",
    "    del skipprint\n",
    "#     del bestmodels\n",
    "    del numbest\n",
    "    del count\n",
    "    del xplot\n",
    "    del yplot\n",
    "    del tempvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L)\n",
    "print(runnumbers)\n",
    "print(nonb_meanid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_L[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATE HEAD-RELATED CONTOUR PLOTS**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle):                  # function to create contour plots                                                      # use this to generate contour plots with streams, wells, return locations, infiltration areas and add x axis titles\n",
    "    extent = (0, ncol, 0, nrow)                                                                   # sets plot boundaries (x0,x1,y0,y1)\n",
    "    for t in np.arange(3):                                                                        # one plot for each steady state condition\n",
    "        if t==0:\n",
    "            h=data_ntna\n",
    "        elif t==1:\n",
    "            h=data_ytna\n",
    "        else:\n",
    "            h=data_ytya\n",
    "        h[h==0]=np.nan                                                                            # remove false zero values to improve color fill limits\n",
    "        levels = np.arange(np.nanmin(h),np.nanmax(h),(np.nanmax(h)-np.nanmin(h))/100)             # creates an array of values used to determine which contour values to draw\n",
    "        ax1[t].invert_yaxis()                                                                     # reverse y axis direction so that row 0 is at the top\n",
    "\n",
    "#         c = ax1[t].contour(h, extent=extent, levels=levels, colors='SteelBlue')                 # plot contours for all rows & columns in layer 1\n",
    "        im = ax1[t].imshow(h,cmap=cm.viridis)                                                     # plot head as a colormap\n",
    "        divider = make_axes_locatable(ax1[t])                                                     # set up colorbar location (need to import make_axes_locatable - see top cell)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)                                   # place colorbar axes on right side of each subplot\n",
    "        plt.colorbar(mappable=im, cax = cax)                                                      # draw colorbar\n",
    "        ax1[t].plot(str_cols, str_rows+.5, c='DarkBlue')                                          # plot stream location (col = x, row = y)\n",
    "        for ij in np.arange(np.shape(data_basis_sequence)[0]):\n",
    "            ax1[t].scatter(data_column_sequence[ij], data_row_sequence[ij], c='White')\n",
    "        if t>0:\n",
    "            ax1[t].scatter(well1[2], well1[1], c='DarkRed')                                       # plot town well location (col = x, row = y)\n",
    "            ax1[t].scatter(return_loc,25, c='DarkRed')                                            # plots town return location (col = x, row = y)\n",
    "            townrect = patches.Rectangle((rNWc[2],rNWc[1]),2,2,linewidth=1,\n",
    "                 edgecolor='DarkRed',facecolor='none')\n",
    "            ax1[t].add_patch(townrect)\n",
    "        if t>1:\n",
    "            ax1[t].scatter(well2[2], well2[1], c='Red')                                           # plot irrigation well location (col = x, row = y)\n",
    "            farmrect = patches.Rectangle((fNWc[1],fNWc[0]),2,2,linewidth=1,\n",
    "                 edgecolor='Red',facecolor='none')\n",
    "            ax1[t].add_patch(farmrect)                                                            # plot farm irrigation area\n",
    "        if t==0:                                       \n",
    "            ax1[t].set_xlabel('ntna')                                                             # label x axis to identify steady state condition\n",
    "        elif t==1:      \n",
    "            ax1[t].set_xlabel('ytna')\n",
    "            plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "        else:\n",
    "            ax1[t].set_xlabel('ytya') \n",
    "\n",
    "if run_sections>-1:\n",
    "    print()\n",
    "    plottitle='ML head in top layer'\n",
    "    minval=0                                                                                          # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=headML_ss_ntna\n",
    "    data_ntna[np.isnan(data_ntna)]=-1\n",
    "    data_ytna=headML_ss_ytna\n",
    "    data_ytya=headML_ss_ytya\n",
    "    f3aa,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle) \n",
    "    plt.show(f3aa)  \n",
    "\n",
    "    print()\n",
    "    plottitle='Mean head in top layer over all models'\n",
    "    minval=0                                                                                          # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=headmean_ss_ntna\n",
    "    data_ntna[np.isnan(data_ntna)]=-1\n",
    "    data_ytna=headmean_ss_ytna\n",
    "    data_ytya=headmean_ss_ytya\n",
    "    f3a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle) \n",
    "    plt.show(f3a)  \n",
    "\n",
    "    plottitle='Standard deviation of head in top layer over all models'\n",
    "    minval=0                                                                                          # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=headvar_ss_ntna\n",
    "    data_ytna=headvar_ss_ntna\n",
    "    data_ytya=headvar_ss_ntna\n",
    "    f3b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f3b)     \n",
    "\n",
    "    print()\n",
    "    plottitle='Mean drawdown in top layer due to agriculture over all models'\n",
    "    minval=0                                                                                          # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytya=ddmean\n",
    "    f7a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f7a)     \n",
    "\n",
    "    print()\n",
    "    plottitle='Standard deviation of drawdown in top layer due to agriculture over all models'\n",
    "    minval=0                                                                                          # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytya=ddvar\n",
    "    f7b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f7b)     \n",
    "\n",
    "\n",
    "if run_sections>0:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        print()\n",
    "        plottitle='Mean head in top layer over models of concern'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=moc_headmean_ss_ntna\n",
    "        data_ytna=moc_headmean_ss_ytna\n",
    "        data_ytya=moc_headmean_ss_ytya\n",
    "        f4a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f4a)     \n",
    "\n",
    "        plottitle='Standard deviation of head in top layer over MOCs'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=moc_headvar_ss_ntna\n",
    "        data_ytna=moc_headvar_ss_ntna\n",
    "        data_ytya=moc_headvar_ss_ntna\n",
    "        f4b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f4b)     \n",
    "\n",
    "        print()\n",
    "        plottitle='Mean head in top layer over other models'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=other_headmean_ss_ntna\n",
    "        data_ytna=other_headmean_ss_ytna\n",
    "        data_ytya=other_headmean_ss_ytya\n",
    "        f5a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f5a)     \n",
    "\n",
    "        plottitle='Standard deviation of head in top layer over other models'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=other_headvar_ss_ntna\n",
    "        data_ytna=other_headvar_ss_ntna\n",
    "        data_ytya=other_headvar_ss_ntna\n",
    "        f5b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f5b)     \n",
    "\n",
    "if run_sections>1:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        print()\n",
    "        plottitle='Absolute difference in mean head in top layer models of concern versus other models'\n",
    "        minval=0.1                                                                                    # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=meandiff_ntna\n",
    "        data_ytna=meandiff_ytna\n",
    "        data_ytya=meandiff_ytya\n",
    "        f6a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f6a)     \n",
    "\n",
    "        print()\n",
    "        plottitle='Sum of standard deviations in top layer models of concern and other models'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=sumvar_ntna\n",
    "        data_ytna=sumvar_ytna\n",
    "        data_ytya=sumvar_ytya\n",
    "        f6b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f6b)     \n",
    "\n",
    "        print()\n",
    "        plottitle='Mean abs head difference, top layer, MOCs versus other models divided by sum of standard deviations rounded to 1 sig fig'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=di_std_ntna\n",
    "        data_ytna=di_std_ytna\n",
    "        data_ytya=di_std_ytya\n",
    "        f6c,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,np.round(10*data_ntna)/10,np.round(10*data_ytna)/10,\n",
    "             np.round(10*data_ytya)/10,minval,plottitle)\n",
    "        plt.show(f6c)\n",
    "\n",
    "        print()\n",
    "        plottitle='Summed likelihood of models with overlapping head values between MOCs and other models - smaller is better'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=overlap_ntna_head\n",
    "        data_ytna=overlap_ytna_head\n",
    "        data_ytya=overlap_ytya_head\n",
    "        f6d,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "        plt.show(f6d)     \n",
    "\n",
    "        print()\n",
    "        plottitle='Mean abs head difference, top layer, MOCs versus other models multiplied by (1-overlap) - rounded to 1 sig fig'\n",
    "        minval=0                                                                                      # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "        data_ntna=di_overlap_ntna\n",
    "        data_ytna=di_overlap_ytna\n",
    "        data_ytya=di_overlap_ytya\n",
    "        f6e,ax1 = plt.subplots(1,3,figsize=(20,4))                                                     # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "        make_contour_plot(ncol,nrow,np.round(10*data_ntna)/10,np.round(10*data_ytna)/10,\n",
    "             np.round(10*data_ytya)/10,minval,plottitle)\n",
    "        plt.show(f6e)     \n",
    "\n",
    "        #Export files needed for multi-stakeholder comparisons:\n",
    "        #To import, use np.load()\n",
    "        comparison_directory()               #change directory to current stakeholder and stage\n",
    "        np.save(prefix + 'di_std', di_std_ytna)\n",
    "        output_directory()\n",
    "\n",
    "    del minval\n",
    "    del data_ntna\n",
    "    del data_ytna\n",
    "    del data_ytya\n",
    "    del plottitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATE PARTICLE-RELATED CONTOUR PLOTS**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_sections>2:\n",
    "    plottitle='Fraction of models predicting capture of recharge in town cell at each cell in top layer over all models'\n",
    "    minval=0                                                                                           # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytna=w1capgrid[1][:][:]\n",
    "    data_ytya=w1capgrid[2][:][:]\n",
    "    \n",
    "    f8a,ax1 = plt.subplots(1,3,figsize=(20,4))                                                          # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f8a)\n",
    "\n",
    "    print()\n",
    "    plottitle='Fraction of models predicting capture or recharge in ag cell at each cell in top layer over all models'\n",
    "    minval=0                                                                                           # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytna=np.random.rand(np.shape(ddmean)[0],np.shape(ddmean)[0])*1e-10\n",
    "    data_ytya=w2capgrid[2][:][:]\n",
    "    f8b,ax1 = plt.subplots(1,3,figsize=(20,4))                                                          # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f8b)\n",
    "\n",
    "    print()\n",
    "    plottitle='Fraction of models predicting capture or recharge in stream at each cell in top layer over all models'\n",
    "    minval=0                                                                                           # minimum allowable value ... only used for difference plot to identify measurable differences\n",
    "    data_ntna=strcapgrid[0][:][:]\n",
    "    data_ytna=strcapgrid[1][:][:]\n",
    "    data_ytya=strcapgrid[2][:][:]\n",
    "    f8c,ax1 = plt.subplots(1,3,figsize=(20,4))                                                          # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    make_contour_plot(ncol,nrow,data_ntna,data_ytna,data_ytya,minval,plottitle)\n",
    "    plt.show(f8c)\n",
    "\n",
    "    del minval                                                                                         # clear temporary variables\n",
    "    del plottitle\n",
    "    del data_ntna\n",
    "    del data_ytna\n",
    "    del data_ytya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATE TRANSECT PLOTS ALONG STREAM**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle):\n",
    "    matrixdim=data_ntna.ndim\n",
    "    if matrixdim==1:                                                                              # single trace\n",
    "        numloops=1\n",
    "        xplot=np.shape(data_ntna)[0]\n",
    "    else:                                                                                         # trace for each model run\n",
    "        numloops=np.shape(data_ntna)[0]\n",
    "        xplot=np.shape(data_ntna)[1]\n",
    "    for t in np.arange(3):                                                                        # one plot for each steady state condition\n",
    "        for i in np.arange(numloops):\n",
    "            if matrixdim==1:\n",
    "                if t==0:                                                                          # label x axis to identify steady state condition\n",
    "                    c = ax1.plot(np.arange(xplot),data_ntna,color='blue',label='ntna')            # plot contours for all rows & columns in layer 1\n",
    "                elif t==1:\n",
    "                    c = ax1.plot(np.arange(xplot),data_ytna,color='red',label='ytna')             # plot contours for all rows & columns in layer 1\n",
    "                    plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "                else:\n",
    "                    c = ax1.plot(np.arange(xplot),data_ytya,color='green',label='ytya')           # plot contours for all rows & columns in layer 1\n",
    "                    ax1.legend()\n",
    "            else:\n",
    "                if t==0:                                                                          # label x axis to identify steady state condition\n",
    "                    c = ax1[t].plot(np.arange(xplot),data_ntna[i])                                # plot contours for all rows & columns in layer 1\n",
    "                    ax1[t].set_xlabel('ntna')\n",
    "                elif t==1:\n",
    "                    c = ax1[t].plot(np.arange(xplot),data_ytna[i])                                # plot contours for all rows & columns in layer 1\n",
    "                    ax1[t].set_xlabel('ytna')\n",
    "                    plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "                else:\n",
    "                    c = ax1[t].plot(np.arange(xplot),data_ytya[i])                                # plot contours for all rows & columns in layer 1\n",
    "                    ax1[t].set_xlabel('ytya')                    \n",
    "    \n",
    "    \n",
    "if run_sections>-1:\n",
    "    plottitle='Streamflow along length of stream for every model'\n",
    "    data_ntna=allflows_ss_ntna\n",
    "    data_ytna=allflows_ss_ytna\n",
    "    data_ytya=allflows_ss_ytya\n",
    "    f10a,ax1 = plt.subplots(1,3,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f10a)                                                      \n",
    "\n",
    "    plottitle='ML streamflow along length of stream'\n",
    "    data_ntna=flowML_ss_ntna\n",
    "    data_ytna=flowML_ss_ytna\n",
    "    data_ytya=flowML_ss_ytya\n",
    "    f10aa,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f10aa)                                                      \n",
    "\n",
    "    plottitle='Mean streamflow along length of stream'\n",
    "    data_ntna=flowmean_ss_ntna\n",
    "    data_ytna=flowmean_ss_ytna\n",
    "    data_ytya=flowmean_ss_ytya\n",
    "    f10b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f10b)                                                      \n",
    "\n",
    "    plottitle='Standard deviation of streamflow along length of stream'\n",
    "    data_ntna=flowvar_ss_ntna\n",
    "    data_ytna=flowvar_ss_ytna\n",
    "    data_ytya=flowvar_ss_ytya\n",
    "    f10c,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f10c)                                                      \n",
    "\n",
    "    plottitle='Leakage along length of stream for every model'\n",
    "    data_ntna=allleaks_ss_ntna\n",
    "    data_ytna=allleaks_ss_ytna\n",
    "    data_ytya=allleaks_ss_ytya\n",
    "    f11a,ax1 = plt.subplots(1,3,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f11a)                                                      \n",
    "\n",
    "    plottitle='Mean leakage along length of stream'\n",
    "    data_ntna=leakmean_ss_ntna\n",
    "    data_ytna=leakmean_ss_ytna\n",
    "    data_ytya=leakmean_ss_ytya\n",
    "    f11b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f11b)                                                      \n",
    "\n",
    "    plottitle='Standard deviation of leakage along length of stream'\n",
    "    data_ntna=leakvar_ss_ntna\n",
    "    data_ytna=leakvar_ss_ytna\n",
    "    data_ytya=leakvar_ss_ytya\n",
    "    f11c,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "    make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "    plt.show(f11c)                                                      \n",
    "\n",
    "if run_sections>0:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "\n",
    "        plottitle='Mean flow along length of stream - MOCs'\n",
    "        data_ntna=moc_flowmean_ss_ntna\n",
    "        data_ytna=moc_flowmean_ss_ytna\n",
    "        data_ytya=moc_flowmean_ss_ytya\n",
    "        f12a,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f12a)                                                      \n",
    "\n",
    "        plottitle='Standard deviation of flow along length of stream - MOCs'\n",
    "        data_ntna=moc_flowvar_ss_ntna\n",
    "        data_ytna=moc_flowvar_ss_ytna\n",
    "        data_ytya=moc_flowvar_ss_ytya\n",
    "        f12b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f12b)                                                      \n",
    "\n",
    "        plottitle='Mean flow along length of stream - other models'\n",
    "        data_ntna=other_flowmean_ss_ntna\n",
    "        data_ytna=other_flowmean_ss_ytna\n",
    "        data_ytya=other_flowmean_ss_ytya\n",
    "        f12c,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f12c)                                                      \n",
    "\n",
    "        plottitle='Standard deviation of flow along length of stream - other models'\n",
    "        data_ntna=other_flowvar_ss_ntna\n",
    "        data_ytna=other_flowvar_ss_ytna\n",
    "        data_ytya=other_flowvar_ss_ytya\n",
    "        f12d,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f12d)                                                      \n",
    "\n",
    "if run_sections>1:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        plottitle='Difference in mean flow - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_flowmean_ss_ntna-other_flowmean_ss_ntna)\n",
    "        data_ytna=np.abs(moc_flowmean_ss_ytna-other_flowmean_ss_ytna)\n",
    "        data_ytya=np.abs(moc_flowmean_ss_ytya-other_flowmean_ss_ytya)\n",
    "        f13a,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f13a)                                                      \n",
    "\n",
    "        plottitle='Sum of standard deviations of flow - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_flowvar_ss_ntna+other_flowvar_ss_ntna)\n",
    "        data_ytna=np.abs(moc_flowvar_ss_ytna+other_flowvar_ss_ytna)\n",
    "        data_ytya=np.abs(moc_flowvar_ss_ytya+other_flowvar_ss_ytya)\n",
    "        f13b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f13b)                                                      \n",
    "\n",
    "        plottitle='Difference in mean flow divided by sum of st devs - MOCs vs other models'\n",
    "        tempvar=np.abs(moc_flowvar_ss_ntna+other_flowvar_ss_ntna)\n",
    "        data_ntna=np.abs(moc_flowmean_ss_ntna-other_flowmean_ss_ntna)/tempvar\n",
    "        tempvar=np.abs(moc_flowvar_ss_ytna+other_flowvar_ss_ytna)\n",
    "        data_ytna=np.abs(moc_flowmean_ss_ytna-other_flowmean_ss_ytna)/tempvar\n",
    "        tempvar=np.abs(moc_flowvar_ss_ytya+other_flowvar_ss_ytya)\n",
    "        data_ytya=np.abs(moc_flowmean_ss_ytya-other_flowmean_ss_ytya)/tempvar\n",
    "        f13c,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f13c)                                                      \n",
    "\n",
    "        plottitle='Degree of overlap of flow - MOCs vs other models'\n",
    "        data_ntna=overlap_ntna_flow\n",
    "        data_ytna=overlap_ytna_flow\n",
    "        data_ytya=overlap_ytya_flow\n",
    "        f13d,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f13d)                                                      \n",
    "\n",
    "        plottitle='Difference in mean flow times (1-overlap) - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_flowmean_ss_ntna-other_flowmean_ss_ntna)*(1-overlap_ntna_flow)\n",
    "        data_ytna=np.abs(moc_flowmean_ss_ytna-other_flowmean_ss_ytna)*(1-overlap_ytna_flow)\n",
    "        data_ytya=np.abs(moc_flowmean_ss_ytya-other_flowmean_ss_ytya)*(1-overlap_ytya_flow)\n",
    "        f13e,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f13e)                                                      \n",
    "\n",
    "if run_sections>0:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        plottitle='Mean leakage along length of stream - MOCs'\n",
    "        data_ntna=moc_leakmean_ss_ntna\n",
    "        data_ytna=moc_leakmean_ss_ytna\n",
    "        data_ytya=moc_leakmean_ss_ytya\n",
    "        f14a,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f14a)                                                      \n",
    "\n",
    "        plottitle='Standard deviation of leakage along length of stream - MOCs'\n",
    "        data_ntna=moc_leakvar_ss_ntna\n",
    "        data_ytna=moc_leakvar_ss_ytna\n",
    "        data_ytya=moc_leakvar_ss_ytya\n",
    "        f14b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f14b)                                                      \n",
    "\n",
    "        plottitle='Mean leakage along length of stream - other models'\n",
    "        data_ntna=other_leakmean_ss_ntna\n",
    "        data_ytna=other_leakmean_ss_ytna\n",
    "        data_ytya=other_leakmean_ss_ytya\n",
    "        f14c,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f14c)                                                      \n",
    "\n",
    "        plottitle='Standard deviation of leakage along length of stream - other models'\n",
    "        data_ntna=other_leakvar_ss_ntna\n",
    "        data_ytna=other_leakvar_ss_ytna\n",
    "        data_ytya=other_leakvar_ss_ytya\n",
    "        f14d,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f14d)                                                      \n",
    "\n",
    "if run_sections>1:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        plottitle='Difference in mean leakage - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_leakmean_ss_ntna-other_leakmean_ss_ntna)\n",
    "        data_ytna=np.abs(moc_leakmean_ss_ytna-other_leakmean_ss_ytna)\n",
    "        data_ytya=np.abs(moc_leakmean_ss_ytya-other_leakmean_ss_ytya)\n",
    "        f15a,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f15a)                                                      \n",
    "\n",
    "        plottitle='Sum of standard deviations of leakage - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_leakvar_ss_ntna+other_leakvar_ss_ntna)\n",
    "        data_ytna=np.abs(moc_leakvar_ss_ytna+other_leakvar_ss_ytna)\n",
    "        data_ytya=np.abs(moc_leakvar_ss_ytya+other_leakvar_ss_ytya)\n",
    "        f15b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f15b)                                                      \n",
    "\n",
    "# THIS ISN'T WORKING RIGHT NOW ... NOT SURE WHY\n",
    "#     plottitle='Difference in mean leakage divided by sum of st devs - MOCs vs other models'\n",
    "#     temvpar=np.abs(moc_leakvar_ss_ntna+other_leakvar_ss_ntna)\n",
    "#     data_ntna=np.abs(moc_leakmean_ss_ntna-other_leakmean_ss_ntna)/tempvar\n",
    "#     temvpar=np.abs(moc_leakvar_ss_ytna+other_leakvar_ss_ytna)\n",
    "#     data_ytna=np.abs(moc_leakmean_ss_ytna-other_leakmean_ss_ytna)/tempvar\n",
    "#     temvpar=np.abs(moc_leakvar_ss_ytya+other_leakvar_ss_ytya)\n",
    "#     data_ytya=np.abs(moc_leakmean_ss_ytya-other_leakmean_ss_ytya)/tempvar\n",
    "#     f15,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "#     make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "#     plt.show(f15)                                                      \n",
    "\n",
    "if run_sections>2:\n",
    "    if np.shape(moc_ids_counter)[0] > 0:\n",
    "        plottitle='Degree of overlap of leakage - MOCs vs other models'\n",
    "        data_ntna=overlap_ntna_flow\n",
    "        data_ytna=overlap_ytna_flow\n",
    "        data_ytya=overlap_ytya_flow\n",
    "        f9a,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f9a)                                                      \n",
    "\n",
    "        plottitle='Difference in mean leakage times (1-overlap) - MOCs vs other models'\n",
    "        data_ntna=np.abs(moc_flowmean_ss_ntna-other_flowmean_ss_ntna)*(1-overlap_ntna_flow)\n",
    "        data_ytna=np.abs(moc_flowmean_ss_ytna-other_flowmean_ss_ytna)*(1-overlap_ytna_flow)\n",
    "        data_ytya=np.abs(moc_flowmean_ss_ytya-other_flowmean_ss_ytya)*(1-overlap_ytya_flow)\n",
    "        f9b,ax1 = plt.subplots(1,1,figsize=(20,4))           \n",
    "        make_profile_plot(data_ntna,data_ytna,data_ytya,plottitle)\n",
    "        plt.show(f9b)                                                      \n",
    "\n",
    "if run_sections>2:\n",
    "    del tempvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATE HISTOGRAMS AT SELECTED LOCATIONS**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Locations of observation points, wells, and return flow')\n",
    "f16,ax1 = plt.subplots(1,1,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "extent = (0, ncol, 0, nrow)                                                                        # sets plot boundaries (x0,x1,y0,y1)\n",
    "ax1.invert_yaxis()                                                                                 # reverses y axis direction so that row 0 is at the top\n",
    "ax1.set_aspect(aspect='equal')\n",
    "w1=ax1.scatter(well1[2], well1[1], c='DarkRed')                                                    # plot town well location (col = x, row = y)\n",
    "w2=ax1.scatter(well2[2], well2[1], c='Red')                                                        # plot irrigation well location (col = x, row = y)\n",
    "hobs=ax1.scatter(displaycolumn, displayrow, c='LightGreen')                                        # plot selected head location \n",
    "strobs=ax1.scatter(strdisplaycolumn, 25.5, c='Blue')                                               # plot selected stream flow location \n",
    "townret=ax1.scatter(return_loc, 25.5, c='Orange')                                                  # plot town return to stream \n",
    "ax1.plot(str_cols, str_rows+.5, c='DarkBlue')                                                      # plot stream location (col = x, row = y)\n",
    "townrect = patches.Rectangle((rNWc[2],rNWc[1]),2,2,linewidth=1,edgecolor='Red',facecolor='none')\n",
    "townmidx = rNWc[2]+1\n",
    "townmidy = rNWc[1]+1\n",
    "town_rech=ax1.scatter(townmidx, townmidy, c='Yellow')                                                                # plot town well location (col = x, row = y)\n",
    "ax1.add_patch(townrect)                                                                            # plots town irrigation area\n",
    "farmrect = patches.Rectangle((fNWc[1],fNWc[0]),2,2,linewidth=1,edgecolor='Red',facecolor='none')\n",
    "agmidx = fNWc[1]+1\n",
    "agmidy = fNWc[0]+1\n",
    "ag_rech=ax1.scatter(agmidx, agmidy, c='DarkGreen')                                                 # plot town well location (col = x, row = y)\n",
    "ax1.add_patch(farmrect)                                                                            # plots farm irrigation area\n",
    "f16.legend([w1,w2,townret,hobs,strobs,town_rech,ag_rech],['town well','farm well','return flow',\n",
    "     'head obs','flow obs','town recharge','farm'],loc=2)                                          # add legend center right\n",
    "plt.title('Locations of observation points, wells, and return flow')\n",
    "plt.show(f16)                                                                                      # display plot (not always necessary)\n",
    "\n",
    "def plot_single_histograms(data_ntna,data_ytna,data_ytya,displayrow,displaycolumn,plottitle):\n",
    "    matrixdim=data_ntna.ndim\n",
    "    for j in np.arange(3):                                                                         # create plot for each steady state condition\n",
    "        tempvals=[]\n",
    "        tempws=[]\n",
    "        for i in np.arange(np.shape(data_ntna)[0]):\n",
    "            if matrixdim==2:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            else:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            tempvals.append(addval)\n",
    "            tempws.append(addweight)\n",
    "        c = ax1[j].hist(tempvals,weights=tempws)                                                  # plots histogram of head in layer 1 across all models\n",
    "        if j==0:                                                                                  # label x axis to identify steady state condition\n",
    "            ax1[j].set_xlabel('ntna')\n",
    "        elif j==1:\n",
    "            ax1[j].set_xlabel('ytna')\n",
    "            plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "        else:\n",
    "            ax1[j].set_xlabel('ytya')\n",
    "        ax1[j].set_ylabel('Summed Likelihood')\n",
    "\n",
    "def plot_double_histograms(data_ntna,data_ytna,data_ytya,moc_ids_counter,other_ids_counter,\n",
    "     displayrow,displaycolumn,plottitle):\n",
    "    matrixdim=data_ntna.ndim\n",
    "    \n",
    "    for j in np.arange(3):    \n",
    "        tempvals=[]\n",
    "        tempws=[]\n",
    "        for i in moc_ids_counter:                                                                 # plot drawdown due to ag at steady state\n",
    "            if matrixdim==2:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            else:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            if addval>0:\n",
    "                tempvals.append(addval)\n",
    "                tempws.append(addweight)\n",
    "        tempvals2=[]\n",
    "        tempws2=[]\n",
    "        for i in other_ids_counter:                                                               # plot drawdown due to ag at steady state\n",
    "            if matrixdim==2:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            else:\n",
    "                if j==0:\n",
    "                    addval=data_ntna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                elif j==1:\n",
    "                    addval=data_ytna[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "                else:\n",
    "                    addval=data_ytya[i][displayrow][displaycolumn]\n",
    "                    addweight=L[i]\n",
    "            if addval>0:\n",
    "                tempvals2.append(addval)\n",
    "                tempws2.append(addweight)\n",
    "\n",
    "        minval=min(np.min(tempvals),np.min(tempvals2))\n",
    "        maxval=max(np.max(tempvals),np.max(tempvals2))        \n",
    "        bins=minval+np.arange(20)*(maxval-minval)/20\n",
    "\n",
    "        c = ax1[j].hist(tempvals,weights=tempws,bins=bins,alpha=0.5,color='red',label='MOC')                # plot contours for all rows & columns in layer 1\n",
    "        c = ax1[j].hist(tempvals2,weights=tempws2,bins=bins,alpha=0.5,color='blue',label='other')             # plots contours for all rows & columns in layer 1\n",
    "        if j==0:\n",
    "            ax1[j].set_xlabel('ntna')\n",
    "        elif j==1:\n",
    "            ax1[j].set_xlabel('ytna')\n",
    "        else:\n",
    "            ax1[j].set_xlabel('ytya')        \n",
    "        ax1[j].set_ylabel('Summed Likelihood')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.figtext(0.5, 0.95, plottitle, ha='center', va='center')\n",
    "        \n",
    "\n",
    "if run_sections>0:\n",
    "    plottitle='Summed likelihoods of head values at observation well - MOCs and other models'\n",
    "    data_ntna=allheads_ss_ntna\n",
    "    data_ytna=allheads_ss_ytna\n",
    "    data_ytya=allheads_ss_ytya\n",
    "    f17,ax1 = plt.subplots(1,3,figsize=(20,4))                                                         # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    plot_double_histograms(data_ntna,data_ytna,data_ytya,moc_ids_counter,other_ids_counter,\n",
    "         displayrow,displaycolumn,plottitle)\n",
    "    plt.show(f17)\n",
    "\n",
    "#     plottitle='Summed likelihoods of drawdown due to ag at observation point - MOCs and other models'\n",
    "#     data_ntna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "#          np.shape(allheads_ss_ytna)[2])*0\n",
    "#     data_ytna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "#          np.shape(allheads_ss_ytna)[2])*0\n",
    "#     data_ytya=allheads_ss_ytna-allheads_ss_ytya\n",
    "#     f18,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "#     plot_double_histograms(data_ntna,data_ytna,data_ytya,moc_ids_counter,other_ids_counter,\n",
    "#          displayrow,displaycolumn,plottitle)\n",
    "#     plt.show(f18)                                                                                                                 # display plot (not always necessary)\n",
    "\n",
    "#     plottitle='Summed likelihoods of flow values at observation cell - MOCs and other models'\n",
    "#     data_ntna=allflows_ss_ntna\n",
    "#     data_ytna=allflows_ss_ytna\n",
    "#     data_ytya=allflows_ss_ytya\n",
    "#     f19,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "#     plot_double_histograms(data_ntna,data_ytna,data_ytya,moc_ids_counter,other_ids_counter,\n",
    "#          displayrow,strdisplaycolumn,plottitle)\n",
    "#     plt.show(f19)                                                                                                                 # display plot (not always necessary)\n",
    "\n",
    "#     if 'discindex_overlap' in locals():\n",
    "#         plottitle='Normalized discriminatory index'\n",
    "#         f20,ax1 = plt.subplots(1,1,figsize=(20,4))                                                    # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "#         data_ytna=-1*np.sort(-discindex_overlap)\n",
    "#         data_ytna[np.isnan(data_ytna)]=0\n",
    "#         data_ytna=np.reshape(data_ytna, np.shape(data_ytna)[0]*np.shape(data_ytna)[1])\n",
    "#         data_ytna=-np.sort(-data_ytna)\n",
    "#         data_ytna=data_ytna/data_ytna[0]\n",
    "#         c = ax1.plot(np.arange(np.shape(data_ytna)[0]),data_ytna,color=\"blue\",label='overlap') \n",
    "#         data_ytna=-1*np.sort(-discindex_std)\n",
    "#         data_ytna[np.isnan(data_ytna)]=0\n",
    "#         data_ytna=np.reshape(data_ytna, np.shape(data_ytna)[0]*np.shape(data_ytna)[1])\n",
    "#         data_ytna=-np.sort(-data_ytna)\n",
    "#         data_ytna=data_ytna/data_ytna[0]\n",
    "#         c = ax1.plot(np.arange(np.shape(data_ytna)[0]),data_ytna,color=\"red\",label='st-dev') \n",
    "#         ax1.set_xlabel('sorted possible measurement locations')\n",
    "#         ax1.set_ylabel('normalized discriminatory index')\n",
    "#         plt.legend()\n",
    "#         plt.show(f20)\n",
    "\n",
    "elif run_sections>-1 and len(runnumbers)>1:\n",
    "    plottitle='Summed likelihoods of head values at observation well'\n",
    "    data_ntna=allheads_ss_ntna\n",
    "    data_ytna=allheads_ss_ytna\n",
    "    data_ytya=allheads_ss_ytya\n",
    "    f17,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    plot_single_histograms(data_ntna,data_ytna,data_ytya,displayrow,displaycolumn,plottitle)\n",
    "    plt.show(f17)                                                                                     # display plot (not always necessary)plt.show(f9)                                                         # display plot (not always necessary)\n",
    "\n",
    "    plottitle='Summed likelihoods of drawdown due to ag  at observation well'\n",
    "    data_ntna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "         np.shape(allheads_ss_ytna)[2])*0\n",
    "    data_ytna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "         np.shape(allheads_ss_ytna)[2])*0\n",
    "    data_ytya=allheads_ss_ytna-allheads_ss_ytya\n",
    "    f18,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    plot_single_histograms(data_ntna,data_ytna,data_ytya,displayrow,displaycolumn,plottitle)\n",
    "    plt.show(f18)                                                                                     # display plot (not always necessary)plt.show(f9)                                                         # display plot (not always necessary)\n",
    "\n",
    "    plottitle='Summed likelihoods of flow values at observation cell'\n",
    "    data_ntna=allflows_ss_ntna\n",
    "    data_ytna=allflows_ss_ytna\n",
    "    data_ytya=allflows_ss_ytya\n",
    "    f19,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "    plot_single_histograms(data_ntna,data_ytna,data_ytya,displayrow,strdisplaycolumn,plottitle)\n",
    "    plt.show(f19)                                                                                     # display plot (not always necessary)plt.show(f9)                                                         # display plot (not always necessary)\n",
    "\n",
    "    del data_ntna                                                                                     # clear temporary variables\n",
    "    del data_ytna\n",
    "    del data_ytya\n",
    "    del w1\n",
    "    del w2\n",
    "    del hobs\n",
    "    del strobs\n",
    "    del townret\n",
    "    del townrect\n",
    "    del townmidx\n",
    "    del townmidy\n",
    "    del town_rech\n",
    "    del farmrect\n",
    "    del agmidx\n",
    "    del agmidy\n",
    "    del ag_rech\n",
    "    del plottitle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if run_sections>0:\n",
    "#    figure_directory()####\n",
    "#\n",
    "#    figures = [f0,f1,f2,f3aa,f3a,f3b,f4a,f4b,f5a,f5b,f6a,f6b,f6c,f6d,f6e,f7a,f7b,f8a,f8b,f8c,f9a,f9b,f10aa,f10a,f10b,f10c,f11a,f11b,f11c,f12a,f12b,f12c,f12d,f13a,f13b,f13c,f13d,f13e,f14a,f14b,f14c,f14d,f15a,f15b,f16,f17]   # list of figures\n",
    "#    figures = [f0,f1,f2,f3aa,f3a,f3b,f4a,f4b,f5a,f5b,f7a,f7b,f10aa,f10a,f10b,f10c,f11a,f11b,f11c,f12a,f12b,f12c,f12d,f13e,f14a,f14b,f14c,f14d,f15a,f15b,f16,f17,f18,f19]   # list of figures\n",
    "#    fig_names = []                                                              # initialize empty list for figure names\n",
    "#    for i in range(len(figures)):                                               # loop over number of figures\n",
    "#        fig_names.append('f' + str(i) + '.png')                         # create figure names\n",
    "#        figures[i].savefig(fig_names[i])                                        # save figures as a .png files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve head and flow data from the 'truth' model and the ML model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream_obsloc_col=35\n",
    "#head_obsloc=[20,37]\n",
    "\n",
    "#print(trueflows_ss_ytna[stream_obsloc_col][1])\n",
    "#print(allheads_ss_ytya[MLmodelID,head_obsloc[0],head_obsloc[1]])    \n",
    "#print(allheads_ss_ytna[MLmodelID,head_obsloc[0],head_obsloc[1]])    \n",
    "\n",
    "#print(np.shape(farmcappermodel))\n",
    "#print(farmcappermodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY, FOR HECTOR, LOOK AT DRAWDOWN AT TOWN WELL (OBS WELL PLACED AT TOWN WELL)\n",
    "\n",
    "plottitle='Summed likelihoods of drawdown due to ag  at observation well'\n",
    "data_ntna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "     np.shape(allheads_ss_ytna)[2])*0\n",
    "data_ytna=np.random.rand(np.shape(allheads_ss_ytna)[0],np.shape(allheads_ss_ytna)[1],\n",
    "     np.shape(allheads_ss_ytna)[2])*0\n",
    "data_ytya=allheads_ss_ytna-allheads_ss_ytya\n",
    "f18,ax1 = plt.subplots(1,3,figsize=(20,4))                                                        # create & return figure & axes at position (row, col) of size 20x12 inches\n",
    "plot_single_histograms(data_ntna,data_ytna,data_ytya,displayrow,displaycolumn,plottitle)\n",
    "plt.show(f18)                                                                                     # display plot (not always necessary)plt.show(f9)                                                         # display plot (not always necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shows which models lead to the largest (positive) drawdown\n",
    "\n",
    "obslatedrawdown=data_ytya[:,head_obsloc[0],head_obsloc[1]]\n",
    "largestddrunnumbers=np.where(obslatedrawdown==np.max(obslatedrawdown))\n",
    "for i in np.arange(np.shape(largestddrunnumbers)[1]):\n",
    "    print(runnumbers[largestddrunnumbers[0][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestddrunnumbers[0][1]\n",
    "#largestddrunnumbers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
